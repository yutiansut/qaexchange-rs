# é›¶æ‹·è´æ•°æ®åˆ†å‘æ¶æ„

> é«˜æ€§èƒ½ã€é«˜å¯é çš„å®æ—¶æ•°æ®åˆ†å‘ç³»ç»Ÿ

**ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-10-03

---

## ğŸ“‹ ç›®å½•

- [æ¶æ„æ¦‚è§ˆ](#æ¶æ„æ¦‚è§ˆ)
- [é›¶æ‹·è´åˆ†å‘è®¾è®¡](#é›¶æ‹·è´åˆ†å‘è®¾è®¡)
- [å¤šçº§è®¢é˜…ç³»ç»Ÿ](#å¤šçº§è®¢é˜…ç³»ç»Ÿ)
- [å¯é æ€§ä¿è¯](#å¯é æ€§ä¿è¯)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## æ¶æ„æ¦‚è§ˆ

### è®¾è®¡ç›®æ ‡

1. **è¶…ä½å»¶è¿Ÿ**ï¼šP99 < 10Î¼sï¼ˆé›¶æ‹·è´ + å…±äº«å†…å­˜ï¼‰
2. **é«˜åå**ï¼š> 10M msg/sï¼ˆiceoryx2 é›¶æ‹·è´ï¼‰
3. **é«˜å¯é **ï¼šç¡®è®¤æœºåˆ¶ + æ–­ç‚¹ç»­ä¼ 
4. **æ°´å¹³æ‰©å±•**ï¼šå¤š Publisher + å¤š Subscriber

### æ•°æ®æµ

```
æ•°æ®æº (MatchingEngine/AccountSystem)
    â†“
Publisher (rkyv åºåˆ—åŒ–)
    â†“
iceoryx2 å…±äº«å†…å­˜ (é›¶æ‹·è´)
    â†“
    â”œâ”€â†’ Real-time Subscriber (WebSocket) - P99 < 10Î¼s
    â”œâ”€â†’ Delayed Subscriber (Batch) - 100ms å»¶è¿Ÿ
    â””â”€â†’ Historical Subscriber (WAL Replay) - å†å²æ•°æ®
```

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ•°æ®æºå±‚                                â”‚
â”‚  MatchingEngine | AccountSystem | RiskControl               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Publisher å±‚                                â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Trade        â”‚  â”‚ Account      â”‚  â”‚ Market       â”‚      â”‚
â”‚  â”‚ Publisher    â”‚  â”‚ Publisher    â”‚  â”‚ Publisher    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚      â”‚
â”‚         â”‚                 â”‚          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â†“                                  â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚              â”‚  rkyv Serialization â”‚                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            iceoryx2 å…±äº«å†…å­˜æ€»çº¿ (é›¶æ‹·è´)                     â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Topic: trade_events   | 10MB Ring Buffer            â”‚   â”‚
â”‚  â”‚  Topic: account_events | 10MB Ring Buffer            â”‚   â”‚
â”‚  â”‚  Topic: market_l2      | 50MB Ring Buffer            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“            â†“            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Subscriber å±‚                               â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Real-time    â”‚  â”‚ Delayed      â”‚  â”‚ Historical   â”‚      â”‚
â”‚  â”‚ (WebSocket)  â”‚  â”‚ (Batch)      â”‚  â”‚ (WAL Replay) â”‚      â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚      â”‚
â”‚  â”‚ P99 < 10Î¼s   â”‚  â”‚ 100ms batch  â”‚  â”‚ Full history â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## é›¶æ‹·è´åˆ†å‘è®¾è®¡

### 1. åŸºäº iceoryx2 çš„å…±äº«å†…å­˜

**ä¼˜åŠ¿**ï¼š
- é›¶æ‹·è´ï¼šæ•°æ®ç›´æ¥å†™å…¥å…±äº«å†…å­˜
- ä½å»¶è¿Ÿï¼šP99 < 10Î¼sï¼ˆæ— åºåˆ—åŒ–å¼€é”€ï¼‰
- é«˜ååï¼š> 10M msg/s

**å¤ç”¨ qars broadcast_hub**ï¼š

```rust
// qars/libs/qadata/src/broadcast_hub.rs å·²å®ç°
use qars::qadata::broadcast_hub::{BroadcastHub, Topic};

// æˆ‘ä»¬éœ€è¦æ‰©å±•ä»¥æ”¯æŒ rkyv
```

### 2. rkyv é›¶æ‹·è´åºåˆ—åŒ–

```rust
// src/distribution/message.rs

use rkyv::{Archive, Serialize as RkyvSerialize, Deserialize as RkyvDeserialize};

/// åˆ†å‘æ¶ˆæ¯ç±»å‹
#[derive(Debug, Clone, Archive, RkyvSerialize, RkyvDeserialize)]
#[archive(check_bytes)]
pub enum DistributionMessage {
    /// æˆäº¤äº‹ä»¶
    TradeEvent {
        trade_id: [u8; 40],
        order_id: [u8; 40],
        instrument_id: [u8; 16],
        price: f64,
        volume: f64,
        direction: u8,
        timestamp: i64,
    },

    /// è´¦æˆ·æ›´æ–°
    AccountUpdate {
        user_id: [u8; 32],
        balance: f64,
        available: f64,
        margin: f64,
        timestamp: i64,
    },

    /// Level2 è¡Œæƒ…
    MarketL2 {
        instrument_id: [u8; 16],
        bids: [(f64, f64); 10],  // (price, volume)
        asks: [(f64, f64); 10],
        timestamp: i64,
    },

    /// å¿ƒè·³
    Heartbeat {
        publisher_id: [u8; 16],
        sequence: u64,
        timestamp: i64,
    },
}

impl DistributionMessage {
    /// åºåˆ—åŒ–ä¸º rkyv å­—èŠ‚æµ
    pub fn to_rkyv_bytes(&self) -> Vec<u8> {
        rkyv::to_bytes::<_, 2048>(self).unwrap().to_vec()
    }

    /// é›¶æ‹·è´ååºåˆ—åŒ–
    pub fn from_rkyv_bytes(bytes: &[u8]) -> Result<&ArchivedDistributionMessage, String> {
        rkyv::check_archived_root::<DistributionMessage>(bytes)
            .map_err(|e| format!("Deserialization failed: {}", e))
    }
}
```

### 3. Publisher å®ç°

```rust
// src/distribution/publisher.rs

use iceoryx2::prelude::*;
use std::sync::Arc;
use parking_lot::Mutex;

pub struct DistributionPublisher {
    service: Arc<Mutex<ipc::Service<DistributionMessage>>>,
    publisher_id: String,
    sequence: Arc<AtomicU64>,
}

impl DistributionPublisher {
    pub fn new(topic: &str, publisher_id: &str) -> Result<Self, String> {
        let service_name = ServiceName::new(topic)
            .map_err(|e| format!("Invalid topic: {}", e))?;

        let service = zero_copy::Service::new(&service_name)
            .publish_subscribe()
            .max_publishers(10)
            .max_subscribers(1000)
            .subscriber_max_buffer_size(1000)
            .enable_safe_overflow(true)  // è¦†ç›–æ—§æ•°æ®ï¼Œä¸é˜»å¡
            .create::<[u8]>()
            .map_err(|e| format!("Create service failed: {}", e))?;

        let publisher = service.publisher()
            .max_slice_len(2048)
            .create()
            .map_err(|e| format!("Create publisher failed: {}", e))?;

        Ok(Self {
            service: Arc::new(Mutex::new(service)),
            publisher_id: publisher_id.to_string(),
            sequence: Arc::new(AtomicU64::new(0)),
        })
    }

    /// å‘å¸ƒæ¶ˆæ¯ï¼ˆé›¶æ‹·è´ï¼‰
    pub fn publish(&self, msg: DistributionMessage) -> Result<(), String> {
        let bytes = msg.to_rkyv_bytes();

        let service = self.service.lock();
        let publisher = service.publisher()
            .max_slice_len(bytes.len())
            .create()
            .map_err(|e| format!("Get publisher failed: {}", e))?;

        // é›¶æ‹·è´å†™å…¥å…±äº«å†…å­˜
        let mut sample = publisher.loan_slice_uninit(bytes.len())
            .map_err(|e| format!("Loan failed: {}", e))?;

        sample.copy_from_slice(&bytes);

        sample.send()
            .map_err(|e| format!("Send failed: {}", e))?;

        self.sequence.fetch_add(1, Ordering::Relaxed);
        Ok(())
    }

    /// æ‰¹é‡å‘å¸ƒï¼ˆå‡å°‘é”ç«äº‰ï¼‰
    pub fn publish_batch(&self, messages: Vec<DistributionMessage>) -> Result<(), String> {
        let service = self.service.lock();
        let publisher = service.publisher()
            .max_slice_len(2048)
            .create()?;

        for msg in messages {
            let bytes = msg.to_rkyv_bytes();

            let mut sample = publisher.loan_slice_uninit(bytes.len())?;
            sample.copy_from_slice(&bytes);
            sample.send()?;
        }

        Ok(())
    }

    /// å‘é€å¿ƒè·³
    pub fn send_heartbeat(&self) -> Result<(), String> {
        let sequence = self.sequence.load(Ordering::Relaxed);

        let heartbeat = DistributionMessage::Heartbeat {
            publisher_id: {
                let mut id = [0u8; 16];
                let bytes = self.publisher_id.as_bytes();
                let len = bytes.len().min(16);
                id[..len].copy_from_slice(&bytes[..len]);
                id
            },
            sequence,
            timestamp: chrono::Utc::now().timestamp_nanos_opt().unwrap_or(0),
        };

        self.publish(heartbeat)
    }
}
```

### 4. Subscriber å®ç°

```rust
// src/distribution/subscriber.rs

pub struct DistributionSubscriber {
    service: Arc<ipc::Service<[u8]>>,
    subscriber: ipc::Subscriber<[u8]>,
    subscriber_id: String,
    callback: Arc<dyn Fn(DistributionMessage) + Send + Sync>,
}

impl DistributionSubscriber {
    pub fn new<F>(topic: &str, subscriber_id: &str, callback: F) -> Result<Self, String>
    where
        F: Fn(DistributionMessage) + Send + Sync + 'static,
    {
        let service_name = ServiceName::new(topic)?;

        let service = zero_copy::Service::new(&service_name)
            .publish_subscribe()
            .open_or_create::<[u8]>()?;

        let subscriber = service.subscriber()
            .create()?;

        Ok(Self {
            service: Arc::new(service),
            subscriber,
            subscriber_id: subscriber_id.to_string(),
            callback: Arc::new(callback),
        })
    }

    /// å¯åŠ¨æ¥æ”¶å¾ªç¯
    pub fn start(self) -> tokio::task::JoinHandle<()> {
        tokio::spawn(async move {
            loop {
                // é›¶æ‹·è´æ¥æ”¶
                while let Some(sample) = self.subscriber.receive().unwrap() {
                    let bytes = &*sample;

                    // é›¶æ‹·è´ååºåˆ—åŒ–
                    match DistributionMessage::from_rkyv_bytes(bytes) {
                        Ok(archived_msg) => {
                            // è½¬æ¢ä¸º owned
                            let msg: DistributionMessage = archived_msg
                                .deserialize(&mut rkyv::Infallible)
                                .unwrap();

                            (self.callback)(msg);
                        }
                        Err(e) => {
                            log::error!("Deserialize failed: {}", e);
                        }
                    }
                }

                tokio::time::sleep(tokio::time::Duration::from_micros(10)).await;
            }
        })
    }

    /// å¯åŠ¨æ¥æ”¶å¾ªç¯ï¼ˆé˜»å¡ç‰ˆæœ¬ï¼‰
    pub fn run(self) {
        loop {
            while let Some(sample) = self.subscriber.receive().unwrap() {
                let bytes = &*sample;

                match DistributionMessage::from_rkyv_bytes(bytes) {
                    Ok(archived_msg) => {
                        let msg: DistributionMessage = archived_msg
                            .deserialize(&mut rkyv::Infallible)
                            .unwrap();

                        (self.callback)(msg);
                    }
                    Err(e) => {
                        log::error!("Deserialize failed: {}", e);
                    }
                }
            }

            std::thread::sleep(std::time::Duration::from_micros(10));
        }
    }
}
```

---

## å¤šçº§è®¢é˜…ç³»ç»Ÿ

### è®¢é˜…çº§åˆ«

| çº§åˆ« | å»¶è¿Ÿ | ç”¨é€” | å®ç°æ–¹å¼ |
|------|------|------|---------|
| **Real-time** | P99 < 10Î¼s | WebSocket å®æ—¶æ¨é€ | iceoryx2 é›¶æ‹·è´ |
| **Delayed** | ~100ms | æ‰¹é‡å¤„ç†ã€é£æ§ | æ‰¹é‡èšåˆåæ¨é€ |
| **Historical** | ç§’çº§ | å†å²æŸ¥è¯¢ã€å›æµ‹ | WAL Replay |

### Real-time è®¢é˜…

```rust
// src/distribution/realtime_subscriber.rs

pub struct RealtimeSubscriber {
    inner: DistributionSubscriber,
    websocket_sessions: Arc<DashMap<String, WebSocketSession>>,
}

impl RealtimeSubscriber {
    pub fn new(topic: &str) -> Self {
        let sessions = Arc::new(DashMap::new());
        let sessions_clone = sessions.clone();

        let subscriber = DistributionSubscriber::new(
            topic,
            "realtime",
            move |msg| {
                // ç«‹å³æ¨é€åˆ°æ‰€æœ‰ WebSocket ä¼šè¯
                for session in sessions_clone.iter() {
                    session.send(msg.clone()).ok();
                }
            }
        ).unwrap();

        Self {
            inner: subscriber,
            websocket_sessions: sessions,
        }
    }

    pub fn register_session(&self, session_id: String, session: WebSocketSession) {
        self.websocket_sessions.insert(session_id, session);
    }

    pub fn start(self) -> tokio::task::JoinHandle<()> {
        self.inner.start()
    }
}
```

### Delayed è®¢é˜…ï¼ˆæ‰¹é‡å¤„ç†ï¼‰

```rust
// src/distribution/delayed_subscriber.rs

pub struct DelayedSubscriber {
    inner: DistributionSubscriber,
    batch_buffer: Arc<Mutex<Vec<DistributionMessage>>>,
    batch_size: usize,
    batch_interval: Duration,
}

impl DelayedSubscriber {
    pub fn new(topic: &str, batch_size: usize, batch_interval: Duration) -> Self {
        let buffer = Arc::new(Mutex::new(Vec::with_capacity(batch_size)));
        let buffer_clone = buffer.clone();

        let subscriber = DistributionSubscriber::new(
            topic,
            "delayed",
            move |msg| {
                let mut buf = buffer_clone.lock();
                buf.push(msg);
            }
        ).unwrap();

        Self {
            inner: subscriber,
            batch_buffer: buffer,
            batch_size,
            batch_interval,
        }
    }

    pub fn start(self) -> tokio::task::JoinHandle<()> {
        // å¯åŠ¨æ¥æ”¶å¾ªç¯
        let recv_handle = self.inner.start();

        // å¯åŠ¨æ‰¹é‡å¤„ç†å¾ªç¯
        let buffer = self.batch_buffer.clone();
        let batch_size = self.batch_size;
        let interval = self.batch_interval;

        let batch_handle = tokio::spawn(async move {
            let mut ticker = tokio::time::interval(interval);

            loop {
                ticker.tick().await;

                let mut buf = buffer.lock();

                if !buf.is_empty() {
                    let batch: Vec<_> = buf.drain(..).collect();

                    // å¤„ç†æ‰¹é‡æ•°æ®
                    Self::process_batch(batch).await;
                }
            }
        });

        recv_handle
    }

    async fn process_batch(batch: Vec<DistributionMessage>) {
        log::info!("Processing batch of {} messages", batch.len());

        // æ‰¹é‡å†™å…¥æ•°æ®åº“ã€é£æ§æ£€æŸ¥ç­‰
        for msg in batch {
            // TODO: æ‰¹é‡å¤„ç†é€»è¾‘
        }
    }
}
```

### Historical è®¢é˜…ï¼ˆWAL Replayï¼‰

```rust
// src/distribution/historical_subscriber.rs

pub struct HistoricalSubscriber {
    wal_manager: Arc<WalManager>,
}

impl HistoricalSubscriber {
    pub fn new(wal_path: &str) -> Self {
        Self {
            wal_manager: Arc::new(WalManager::new(wal_path)),
        }
    }

    /// å›æ”¾å†å²æ•°æ®
    pub async fn replay<F>(
        &self,
        start_sequence: u64,
        end_sequence: Option<u64>,
        callback: F,
    ) -> Result<(), String>
    where
        F: Fn(DistributionMessage) + Send + Sync,
    {
        self.wal_manager.replay(|entry| {
            if entry.sequence < start_sequence {
                return Ok(());
            }

            if let Some(end_seq) = end_sequence {
                if entry.sequence > end_seq {
                    return Err("Reached end sequence".to_string());
                }
            }

            // è½¬æ¢ WalRecord â†’ DistributionMessage
            let msg = Self::wal_to_distribution_msg(&entry.record)?;

            callback(msg);

            Ok(())
        })
    }

    fn wal_to_distribution_msg(record: &WalRecord) -> Result<DistributionMessage, String> {
        match record {
            WalRecord::TradeExecuted { trade_id, order_id, price, volume, timestamp, .. } => {
                Ok(DistributionMessage::TradeEvent {
                    trade_id: *trade_id,
                    order_id: *order_id,
                    instrument_id: [0u8; 16],  // TODO: ä» WAL ä¸­æå–
                    price: *price,
                    volume: *volume,
                    direction: 0,
                    timestamp: *timestamp,
                })
            }
            _ => Err("Unsupported WAL record type".to_string()),
        }
    }
}
```

---

## å¯é æ€§ä¿è¯

### 1. ç¡®è®¤æœºåˆ¶ï¼ˆACKï¼‰

```rust
// src/distribution/reliable_publisher.rs

pub struct ReliablePublisher {
    inner: DistributionPublisher,
    pending_acks: Arc<DashMap<u64, PendingMessage>>,  // sequence â†’ message
    retry_timeout: Duration,
}

struct PendingMessage {
    message: DistributionMessage,
    sent_at: Instant,
    retry_count: u32,
}

impl ReliablePublisher {
    /// å‘å¸ƒæ¶ˆæ¯ï¼ˆç­‰å¾…ç¡®è®¤ï¼‰
    pub async fn publish_reliable(&self, msg: DistributionMessage) -> Result<u64, String> {
        let sequence = self.inner.sequence.fetch_add(1, Ordering::SeqCst);

        // è®°å½•å¾…ç¡®è®¤
        self.pending_acks.insert(sequence, PendingMessage {
            message: msg.clone(),
            sent_at: Instant::now(),
            retry_count: 0,
        });

        // å‘å¸ƒ
        self.inner.publish(msg)?;

        // ç­‰å¾…ç¡®è®¤ï¼ˆè¶…æ—¶é‡å‘ï¼‰
        self.wait_for_ack(sequence).await
    }

    async fn wait_for_ack(&self, sequence: u64) -> Result<u64, String> {
        let timeout = tokio::time::sleep(self.retry_timeout);
        tokio::pin!(timeout);

        loop {
            tokio::select! {
                _ = &mut timeout => {
                    // è¶…æ—¶ï¼Œé‡å‘
                    if let Some(mut pending) = self.pending_acks.get_mut(&sequence) {
                        pending.retry_count += 1;

                        if pending.retry_count > 3 {
                            return Err("Max retries exceeded".to_string());
                        }

                        log::warn!("Retry sequence {}, count: {}", sequence, pending.retry_count);
                        self.inner.publish(pending.message.clone())?;
                    }
                }
            }

            // æ£€æŸ¥æ˜¯å¦å·²ç¡®è®¤
            if !self.pending_acks.contains_key(&sequence) {
                return Ok(sequence);
            }

            tokio::time::sleep(Duration::from_millis(10)).await;
        }
    }

    /// æ”¶åˆ°ç¡®è®¤
    pub fn on_ack(&self, sequence: u64) {
        self.pending_acks.remove(&sequence);
    }
}

// Subscriber å‘é€ ACK
impl DistributionSubscriber {
    pub fn send_ack(&self, sequence: u64) -> Result<(), String> {
        let ack = DistributionMessage::Ack {
            sequence,
            subscriber_id: {
                let mut id = [0u8; 16];
                let bytes = self.subscriber_id.as_bytes();
                let len = bytes.len().min(16);
                id[..len].copy_from_slice(&bytes[..len]);
                id
            },
            timestamp: chrono::Utc::now().timestamp_nanos_opt().unwrap_or(0),
        };

        // é€šè¿‡åå‘é€šé“å‘é€ ACK
        // TODO: å®ç° ACK é€šé“
        Ok(())
    }
}
```

### 2. æ–­ç‚¹ç»­ä¼ 

```rust
// src/distribution/resumable_subscriber.rs

pub struct ResumableSubscriber {
    inner: DistributionSubscriber,
    checkpoint_manager: Arc<CheckpointManager>,
    last_sequence: Arc<AtomicU64>,
}

impl ResumableSubscriber {
    pub fn new(topic: &str, checkpoint_path: &str) -> Self {
        let checkpoint_mgr = Arc::new(CheckpointManager::new(checkpoint_path));

        // æ¢å¤ä¸Šæ¬¡çš„ sequence
        let last_seq = checkpoint_mgr.load().unwrap_or(0);

        let last_sequence = Arc::new(AtomicU64::new(last_seq));
        let last_seq_clone = last_sequence.clone();
        let checkpoint_mgr_clone = checkpoint_mgr.clone();

        let subscriber = DistributionSubscriber::new(
            topic,
            "resumable",
            move |msg| {
                // æ›´æ–° sequence
                if let Some(seq) = Self::extract_sequence(&msg) {
                    last_seq_clone.store(seq, Ordering::Relaxed);

                    // å®šæœŸä¿å­˜ checkpoint
                    if seq % 1000 == 0 {
                        checkpoint_mgr_clone.save(seq).ok();
                    }
                }

                // å¤„ç†æ¶ˆæ¯
                Self::process_message(msg);
            }
        ).unwrap();

        Self {
            inner: subscriber,
            checkpoint_manager: checkpoint_mgr,
            last_sequence,
        }
    }

    /// ä»æ–­ç‚¹æ¢å¤
    pub async fn resume(&self) -> Result<(), String> {
        let last_seq = self.last_sequence.load(Ordering::Relaxed);

        if last_seq > 0 {
            log::info!("Resuming from sequence {}", last_seq);

            // ä» WAL é‡æ”¾ç¼ºå¤±çš„æ¶ˆæ¯
            let historical = HistoricalSubscriber::new("/data/wal");
            historical.replay(last_seq + 1, None, |msg| {
                Self::process_message(msg);
            }).await?;
        }

        Ok(())
    }

    fn extract_sequence(msg: &DistributionMessage) -> Option<u64> {
        // TODO: ä»æ¶ˆæ¯ä¸­æå– sequence
        None
    }

    fn process_message(msg: DistributionMessage) {
        // TODO: å¤„ç†é€»è¾‘
    }
}

struct CheckpointManager {
    path: String,
}

impl CheckpointManager {
    fn new(path: &str) -> Self {
        std::fs::create_dir_all(path).unwrap();
        Self { path: path.to_string() }
    }

    fn save(&self, sequence: u64) -> Result<(), String> {
        let checkpoint_file = format!("{}/checkpoint", self.path);
        std::fs::write(&checkpoint_file, sequence.to_string())
            .map_err(|e| format!("Save checkpoint failed: {}", e))
    }

    fn load(&self) -> Result<u64, String> {
        let checkpoint_file = format!("{}/checkpoint", self.path);

        match std::fs::read_to_string(&checkpoint_file) {
            Ok(content) => content.parse::<u64>()
                .map_err(|e| format!("Parse checkpoint failed: {}", e)),
            Err(_) => Ok(0),
        }
    }
}
```

### 3. æ•…éšœæ£€æµ‹

```rust
// src/distribution/health_monitor.rs

pub struct HealthMonitor {
    publishers: Arc<DashMap<String, PublisherHealth>>,
    heartbeat_timeout: Duration,
}

struct PublisherHealth {
    last_heartbeat: Instant,
    sequence: u64,
    status: PublisherStatus,
}

#[derive(Debug, Clone, Copy)]
enum PublisherStatus {
    Healthy,
    Degraded,   // å¿ƒè·³å»¶è¿Ÿ
    Failed,     // è¶…æ—¶
}

impl HealthMonitor {
    pub fn new(heartbeat_timeout: Duration) -> Self {
        Self {
            publishers: Arc::new(DashMap::new()),
            heartbeat_timeout,
        }
    }

    /// å¤„ç†å¿ƒè·³
    pub fn on_heartbeat(&self, publisher_id: &str, sequence: u64) {
        self.publishers.entry(publisher_id.to_string())
            .and_modify(|health| {
                health.last_heartbeat = Instant::now();
                health.sequence = sequence;
                health.status = PublisherStatus::Healthy;
            })
            .or_insert(PublisherHealth {
                last_heartbeat: Instant::now(),
                sequence,
                status: PublisherStatus::Healthy,
            });
    }

    /// å¯åŠ¨å¥åº·æ£€æŸ¥
    pub fn start(self: Arc<Self>) -> tokio::task::JoinHandle<()> {
        tokio::spawn(async move {
            let mut ticker = tokio::time::interval(Duration::from_secs(1));

            loop {
                ticker.tick().await;

                for mut entry in self.publishers.iter_mut() {
                    let elapsed = entry.last_heartbeat.elapsed();

                    if elapsed > self.heartbeat_timeout * 2 {
                        entry.status = PublisherStatus::Failed;
                        log::error!("Publisher {} failed (no heartbeat for {:?})",
                            entry.key(), elapsed);
                    } else if elapsed > self.heartbeat_timeout {
                        entry.status = PublisherStatus::Degraded;
                        log::warn!("Publisher {} degraded (heartbeat delayed {:?})",
                            entry.key(), elapsed);
                    }
                }
            }
        })
    }

    /// è·å–æ‰€æœ‰ Publisher çŠ¶æ€
    pub fn get_status(&self) -> Vec<(String, PublisherStatus, u64)> {
        self.publishers.iter()
            .map(|entry| {
                (entry.key().clone(), entry.status, entry.sequence)
            })
            .collect()
    }
}
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†

```rust
// æ‰¹é‡å‘å¸ƒï¼ˆå‡å°‘ç³»ç»Ÿè°ƒç”¨ï¼‰
publisher.publish_batch(vec![msg1, msg2, msg3])?;

// æ‰¹é‡æ¥æ”¶ï¼ˆå‡å°‘ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼‰
while let Some(samples) = subscriber.receive_batch(100).unwrap() {
    for sample in samples {
        process(sample);
    }
}
```

### 2. CPU äº²å’Œæ€§

```rust
// ç»‘å®š Publisher çº¿ç¨‹åˆ°ç‰¹å®š CPU
use core_affinity;

let core_ids = core_affinity::get_core_ids().unwrap();

thread::Builder::new()
    .name("Publisher".to_string())
    .spawn(move || {
        // ç»‘å®šåˆ° CPU 0
        core_affinity::set_for_current(core_ids[0]);

        publisher.run();
    })
    .unwrap();
```

### 3. é¢„åˆ†é…å†…å­˜

```rust
// é¢„åˆ†é… Ring Buffer
let service = zero_copy::Service::new(&service_name)
    .publish_subscribe()
    .subscriber_max_buffer_size(10000)  // 10000 ä¸ªæ¶ˆæ¯
    .enable_safe_overflow(true)         // è¦†ç›–æ—§æ•°æ®
    .create::<[u8]>()?;
```

### 4. Lock-Free æ•°æ®ç»“æ„

```rust
// ä½¿ç”¨ DashMap æ›¿ä»£ Mutex<HashMap>
use dashmap::DashMap;

let sessions: DashMap<String, WebSocketSession> = DashMap::new();

// æ— é”å¹¶å‘è®¿é—®
sessions.insert(id, session);
sessions.get(&id);
```

---

## æ€§èƒ½ç›®æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | å®ç°æ–¹å¼ |
|------|------|---------|
| **åˆ†å‘å»¶è¿Ÿ** | P99 < 10Î¼s | iceoryx2 é›¶æ‹·è´ |
| **ååé‡** | > 10M msg/s | å…±äº«å†…å­˜ + æ‰¹é‡å¤„ç† |
| **å¯é æ€§** | 99.99% | ACK ç¡®è®¤ + æ–­ç‚¹ç»­ä¼  |
| **æ•…éšœæ¢å¤** | < 5s | WAL Replay |
| **å†…å­˜å ç”¨** | < 500MB | Ring Buffer è¦†ç›– |

---

## ç›¸å…³é“¾æ¥

- [å­˜å‚¨æ¶æ„è®¾è®¡](01_STORAGE_ARCHITECTURE.md)
- [æ•…éšœæ¢å¤è®¾è®¡](03_RECOVERY_DESIGN.md)
- [å®æ–½è®¡åˆ’](04_IMPLEMENTATION_PLAN.md)

---

*æœ€åæ›´æ–°: 2025-10-03*
*ç»´æŠ¤è€…: @yutiansut*
