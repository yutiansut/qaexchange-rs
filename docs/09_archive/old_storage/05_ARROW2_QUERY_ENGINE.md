# Arrow2 æŸ¥è¯¢å¼•æ“è®¾è®¡

> åŸºäº Arrow2 + Polars çš„é«˜æ€§èƒ½åˆ—å¼å­˜å‚¨å’ŒæŸ¥è¯¢å¼•æ“

**ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-10-03

---

## ğŸ“‹ ç›®å½•

- [æ¶æ„æ¦‚è§ˆ](#æ¶æ„æ¦‚è§ˆ)
- [Arrow2 é›†æˆæ–¹æ¡ˆ](#arrow2-é›†æˆæ–¹æ¡ˆ)
- [æŸ¥è¯¢å¼•æ“è®¾è®¡](#æŸ¥è¯¢å¼•æ“è®¾è®¡)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [å®æ–½è®¡åˆ’](#å®æ–½è®¡åˆ’)

---

## æ¶æ„æ¦‚è§ˆ

### è®¾è®¡ç›®æ ‡

1. **åˆ—å¼å­˜å‚¨**ï¼šä½¿ç”¨ Arrow2 åˆ—å¼æ ¼å¼ï¼Œä¼˜åŒ–åˆ†ææŸ¥è¯¢
2. **é›¶æ‹·è´æŸ¥è¯¢**ï¼šArrow2 å†…å­˜æ˜ å°„ï¼Œé¿å…æ•°æ®æ‹·è´
3. **å‘é‡åŒ–æ‰§è¡Œ**ï¼šSIMD åŠ é€Ÿï¼Œ100x æ€§èƒ½æå‡
4. **SQL æ”¯æŒ**ï¼šPolars SQL APIï¼Œå…¼å®¹æ ‡å‡† SQL
5. **æµå¼è®¡ç®—**ï¼šæ”¯æŒå¢é‡æŸ¥è¯¢å’Œå®æ—¶èšåˆ

### æ•°æ®æµ

```
å†™å…¥è·¯å¾„ (OLTP):
OrderRequest â†’ WAL (rkyv) â†’ MemTable â†’ SSTable (Arrow2 IPC)
                â†“
             ç¡®è®¤è¿”å›

æŸ¥è¯¢è·¯å¾„ (OLAP):
SQL Query â†’ Polars Parser â†’ Arrow2 Query Engine â†’ Arrow2 RecordBatch
                                    â†“
                           [MemTable | SSTable (mmap)]
                                    â†“
                           é›¶æ‹·è´ + å‘é‡åŒ–æ‰§è¡Œ
```

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      åº”ç”¨å±‚                                  â”‚
â”‚  OLTP (å†™å…¥) | OLAP (æŸ¥è¯¢åˆ†æ)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         å­˜å‚¨å¼•æ“ (Hybrid OLTP + OLAP)                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  OLTP Path       â”‚    â”‚  OLAP Path           â”‚          â”‚
â”‚  â”‚                  â”‚    â”‚                      â”‚          â”‚
â”‚  â”‚  WAL (rkyv)      â”‚    â”‚  Query Engine        â”‚          â”‚
â”‚  â”‚  MemTable        â”‚    â”‚  (Polars + Arrow2)   â”‚          â”‚
â”‚  â”‚  SSTable (rkyv)  â”‚    â”‚                      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â†“                        â†“                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Arrow2 Columnar Storage                      â”‚          â”‚
â”‚  â”‚                                               â”‚          â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚          â”‚
â”‚  â”‚  â”‚ RecordBatchâ”‚  â”‚  Parquet   â”‚             â”‚          â”‚
â”‚  â”‚  â”‚ (MemTable) â”‚  â”‚  (SSTable) â”‚             â”‚          â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Arrow2 é›†æˆæ–¹æ¡ˆ

### 1. åˆ—å¼ MemTable

**å½“å‰ MemTable**ï¼šè¡Œå¼å­˜å‚¨ï¼ˆSkipMapï¼‰
```rust
// ç°æœ‰å®ç° - é€‚åˆ OLTP
SkipMap<Vec<u8>, Vec<u8>>  // Key-Value è¡Œå¼å­˜å‚¨
```

**Arrow2 MemTable**ï¼šåˆ—å¼å­˜å‚¨ï¼ˆé€‚åˆ OLAPï¼‰
```rust
// src/storage/memtable/arrow_memtable.rs

use arrow2::array::*;
use arrow2::chunk::Chunk;
use arrow2::datatypes::*;
use std::sync::Arc;
use parking_lot::RwLock;

/// Arrow2 åˆ—å¼ MemTableï¼ˆç”¨äºåˆ†ææŸ¥è¯¢ï¼‰
pub struct ArrowMemTable {
    schema: Arc<Schema>,
    chunks: Arc<RwLock<Vec<Chunk<Arc<dyn Array>>>>>,
    max_size: usize,  // æœ€å¤§ 128MB
    current_size: usize,
}

impl ArrowMemTable {
    pub fn new(schema: Schema) -> Self {
        Self {
            schema: Arc::new(schema),
            chunks: Arc::new(RwLock::new(Vec::new())),
            max_size: 128 * 1024 * 1024,
            current_size: 0,
        }
    }

    /// æ’å…¥ä¸€æ‰¹æ•°æ®ï¼ˆRecordBatchï¼‰
    pub fn insert_batch(&mut self, chunk: Chunk<Arc<dyn Array>>) -> Result<(), String> {
        let batch_size = chunk.len();

        if self.current_size + batch_size > self.max_size {
            return Err("MemTable full".to_string());
        }

        self.chunks.write().push(chunk);
        self.current_size += batch_size;

        Ok(())
    }

    /// æŸ¥è¯¢æ•°æ®ï¼ˆè¿”å› Arrow2 RecordBatchï¼‰
    pub fn query(&self, filter: Option<&dyn Fn(&Chunk<Arc<dyn Array>>) -> bool>)
        -> Vec<Chunk<Arc<dyn Array>>>
    {
        let chunks = self.chunks.read();

        if let Some(f) = filter {
            chunks.iter()
                .filter(|chunk| f(chunk))
                .cloned()
                .collect()
        } else {
            chunks.clone()
        }
    }

    /// è½¬æ¢ä¸º Polars DataFrame
    pub fn to_polars_df(&self) -> Result<polars::prelude::DataFrame, String> {
        use polars::prelude::*;

        let chunks = self.chunks.read();

        // å°† Arrow2 Chunk è½¬æ¢ä¸º Polars DataFrame
        // Polars å†…éƒ¨ä½¿ç”¨ Arrow2ï¼Œå¯ä»¥é›¶æ‹·è´è½¬æ¢
        let mut dfs = Vec::new();

        for chunk in chunks.iter() {
            // TODO: Arrow2 â†’ Polars è½¬æ¢
            // let df = DataFrame::from_arrow_chunk(chunk, &self.schema)?;
            // dfs.push(df);
        }

        // åˆå¹¶æ‰€æœ‰ DataFrame
        // Ok(concat_df(&dfs)?)
        Err("Not implemented".to_string())
    }
}
```

### 2. Parquet SSTable

**å½“å‰ SSTable**ï¼šè‡ªå®šä¹‰äºŒè¿›åˆ¶æ ¼å¼ï¼ˆrkyvï¼‰

**Arrow2 SSTable**ï¼šParquet æ ¼å¼ï¼ˆåˆ—å¼å‹ç¼©ï¼‰

```rust
// src/storage/sstable/parquet_sstable.rs

use arrow2::io::parquet::write::*;
use arrow2::io::parquet::read::*;
use arrow2::chunk::Chunk;
use arrow2::datatypes::*;
use std::fs::File;

/// Parquet SSTable Builder
pub struct ParquetSSTableBuilder {
    file: File,
    schema: Arc<Schema>,
    writer: FileWriter<File>,
    row_count: usize,
}

impl ParquetSSTableBuilder {
    pub fn new(file_path: &str, schema: Schema) -> Result<Self, String> {
        let file = File::create(file_path)
            .map_err(|e| format!("Create file failed: {}", e))?;

        // Parquet å†™å…¥é…ç½®
        let options = WriteOptions {
            write_statistics: true,
            compression: CompressionOptions::Snappy,  // Snappy å‹ç¼©
            version: Version::V2,
        };

        let encodings = schema.fields.iter()
            .map(|f| Encoding::Plain)  // é»˜è®¤ç¼–ç 
            .collect();

        let writer = FileWriter::try_new(
            file,
            schema.clone(),
            options,
        ).map_err(|e| format!("Create writer failed: {}", e))?;

        Ok(Self {
            file,
            schema: Arc::new(schema),
            writer,
            row_count: 0,
        })
    }

    /// æ·»åŠ ä¸€æ‰¹æ•°æ®
    pub fn add_batch(&mut self, chunk: Chunk<Arc<dyn Array>>) -> Result<(), String> {
        self.writer.write(&chunk)
            .map_err(|e| format!("Write batch failed: {}", e))?;

        self.row_count += chunk.len();

        Ok(())
    }

    /// å®Œæˆå†™å…¥
    pub fn finish(self) -> Result<(), String> {
        self.writer.end(None)
            .map_err(|e| format!("Finish failed: {}", e))?;

        Ok(())
    }
}

/// Parquet SSTable Reader
pub struct ParquetSSTableReader {
    reader: FileReader<File>,
    schema: Arc<Schema>,
    row_count: usize,
}

impl ParquetSSTableReader {
    pub fn open(file_path: &str) -> Result<Self, String> {
        let mut file = File::open(file_path)
            .map_err(|e| format!("Open file failed: {}", e))?;

        let metadata = read_metadata(&mut file)
            .map_err(|e| format!("Read metadata failed: {}", e))?;

        let schema = infer_schema(&metadata)
            .map_err(|e| format!("Infer schema failed: {}", e))?;

        let row_count = metadata.num_rows;

        let reader = FileReader::try_new(file, None, None, None, None)
            .map_err(|e| format!("Create reader failed: {}", e))?;

        Ok(Self {
            reader,
            schema: Arc::new(schema),
            row_count,
        })
    }

    /// è¯»å–æ‰€æœ‰æ•°æ®ï¼ˆé›¶æ‹·è´ï¼‰
    pub fn read_all(&mut self) -> Result<Vec<Chunk<Arc<dyn Array>>>, String> {
        let mut chunks = Vec::new();

        for maybe_chunk in &mut self.reader {
            let chunk = maybe_chunk
                .map_err(|e| format!("Read chunk failed: {}", e))?;

            chunks.push(chunk);
        }

        Ok(chunks)
    }

    /// è¯»å–æŒ‡å®šè¡ŒèŒƒå›´
    pub fn read_range(&mut self, start: usize, end: usize)
        -> Result<Chunk<Arc<dyn Array>>, String>
    {
        // TODO: å®ç°èŒƒå›´è¯»å–
        Err("Not implemented".to_string())
    }

    /// è½¬æ¢ä¸º Polars DataFrame
    pub fn to_polars_df(&mut self) -> Result<polars::prelude::DataFrame, String> {
        use polars::prelude::*;

        // Polars åŸç”Ÿæ”¯æŒ Parquet
        let df = LazyFrame::scan_parquet(
            self.file_path.clone(),
            ScanArgsParquet::default()
        )
        .map_err(|e| format!("Scan parquet failed: {}", e))?
        .collect()
        .map_err(|e| format!("Collect failed: {}", e))?;

        Ok(df)
    }
}
```

### 3. åŒæ¨¡å¼å­˜å‚¨

**è®¾è®¡æ€è·¯**ï¼š
- **OLTP è·¯å¾„**ï¼šrkyv + SkipMapï¼ˆä½å»¶è¿Ÿå†™å…¥ï¼‰
- **OLAP è·¯å¾„**ï¼šArrow2 + Parquetï¼ˆé«˜æ•ˆæŸ¥è¯¢ï¼‰
- **å¼‚æ­¥è½¬æ¢**ï¼šåå°çº¿ç¨‹å°† OLTP æ•°æ®è½¬æ¢ä¸º OLAP æ ¼å¼

```rust
// src/storage/hybrid_storage.rs

pub struct HybridStorage {
    // OLTP è·¯å¾„
    oltp_memtable: Arc<MemTableManager>,  // rkyv SkipMap
    oltp_sstables: Arc<RwLock<Vec<SSTableReader>>>,  // rkyv SSTable

    // OLAP è·¯å¾„
    olap_memtable: Arc<RwLock<ArrowMemTable>>,  // Arrow2 RecordBatch
    olap_sstables: Arc<RwLock<Vec<ParquetSSTableReader>>>,  // Parquet

    // è½¬æ¢å™¨ï¼ˆOLTP â†’ OLAPï¼‰
    converter: Arc<OltpToOlapConverter>,
}

impl HybridStorage {
    /// å†™å…¥æ•°æ®ï¼ˆOLTP è·¯å¾„ï¼‰
    pub fn insert(&self, key: Vec<u8>, value: Vec<u8>) -> Result<(), String> {
        // 1. å†™å…¥ OLTP MemTableï¼ˆä½å»¶è¿Ÿï¼‰
        self.oltp_memtable.insert(key.clone(), value.clone())?;

        // 2. å¼‚æ­¥è½¬æ¢ä¸º OLAP æ ¼å¼
        let converter = self.converter.clone();
        let olap_memtable = self.olap_memtable.clone();

        tokio::spawn(async move {
            if let Ok(chunk) = converter.convert(key, value) {
                olap_memtable.write().insert_batch(chunk).ok();
            }
        });

        Ok(())
    }

    /// æŸ¥è¯¢æ•°æ®ï¼ˆOLAP è·¯å¾„ï¼‰
    pub fn query(&self, sql: &str) -> Result<polars::prelude::DataFrame, String> {
        use polars::prelude::*;

        // 1. ä» OLAP MemTable è·å–æ•°æ®
        let memtable_df = self.olap_memtable.read().to_polars_df()?;

        // 2. ä» OLAP SSTable è·å–æ•°æ®
        let mut sstable_dfs = Vec::new();
        for sstable in self.olap_sstables.read().iter() {
            sstable_dfs.push(sstable.to_polars_df()?);
        }

        // 3. åˆå¹¶æ‰€æœ‰æ•°æ®
        let mut all_dfs = vec![memtable_df];
        all_dfs.extend(sstable_dfs);

        let combined = concat_df(&all_dfs)?;

        // 4. æ‰§è¡Œ SQL æŸ¥è¯¢
        let ctx = SQLContext::new();
        ctx.register("data", combined.lazy());

        let result = ctx.execute(sql)?
            .collect()?;

        Ok(result)
    }
}
```

---

## æŸ¥è¯¢å¼•æ“è®¾è®¡

### 1. Schema å®šä¹‰

```rust
// src/storage/query/schema.rs

use arrow2::datatypes::*;

/// è®¢å•è¡¨ Schema
pub fn order_schema() -> Schema {
    Schema::from(vec![
        Field::new("order_id", DataType::Utf8, false),
        Field::new("user_id", DataType::Utf8, false),
        Field::new("instrument_id", DataType::Utf8, false),
        Field::new("direction", DataType::UInt8, false),  // 0=BUY, 1=SELL
        Field::new("offset", DataType::UInt8, false),     // 0=OPEN, 1=CLOSE
        Field::new("price", DataType::Float64, false),
        Field::new("volume", DataType::Float64, false),
        Field::new("timestamp", DataType::Int64, false),
    ])
}

/// æˆäº¤è¡¨ Schema
pub fn trade_schema() -> Schema {
    Schema::from(vec![
        Field::new("trade_id", DataType::Utf8, false),
        Field::new("order_id", DataType::Utf8, false),
        Field::new("instrument_id", DataType::Utf8, false),
        Field::new("price", DataType::Float64, false),
        Field::new("volume", DataType::Float64, false),
        Field::new("timestamp", DataType::Int64, false),
    ])
}

/// è´¦æˆ·è¡¨ Schema
pub fn account_schema() -> Schema {
    Schema::from(vec![
        Field::new("user_id", DataType::Utf8, false),
        Field::new("balance", DataType::Float64, false),
        Field::new("available", DataType::Float64, false),
        Field::new("frozen", DataType::Float64, false),
        Field::new("margin", DataType::Float64, false),
        Field::new("timestamp", DataType::Int64, false),
    ])
}
```

### 2. æŸ¥è¯¢å¼•æ“

```rust
// src/storage/query/engine.rs

use polars::prelude::*;
use std::sync::Arc;

pub struct QueryEngine {
    storage: Arc<HybridStorage>,
    ctx: SQLContext,
}

impl QueryEngine {
    pub fn new(storage: Arc<HybridStorage>) -> Self {
        let ctx = SQLContext::new();

        Self { storage, ctx }
    }

    /// æ‰§è¡Œ SQL æŸ¥è¯¢
    pub fn query(&mut self, sql: &str) -> Result<DataFrame, String> {
        // æ³¨å†Œè¡¨
        self.register_tables()?;

        // æ‰§è¡ŒæŸ¥è¯¢
        let result = self.ctx.execute(sql)
            .map_err(|e| format!("Query failed: {}", e))?
            .collect()
            .map_err(|e| format!("Collect failed: {}", e))?;

        Ok(result)
    }

    /// æ³¨å†Œè¡¨
    fn register_tables(&mut self) -> Result<(), String> {
        // è®¢å•è¡¨
        let orders_df = self.storage.get_orders()?;
        self.ctx.register("orders", orders_df.lazy());

        // æˆäº¤è¡¨
        let trades_df = self.storage.get_trades()?;
        self.ctx.register("trades", trades_df.lazy());

        // è´¦æˆ·è¡¨
        let accounts_df = self.storage.get_accounts()?;
        self.ctx.register("accounts", accounts_df.lazy());

        Ok(())
    }

    /// é¢„å®šä¹‰æŸ¥è¯¢ï¼šç”¨æˆ·äº¤æ˜“ç»Ÿè®¡
    pub fn user_trade_stats(&mut self, user_id: &str) -> Result<DataFrame, String> {
        let sql = format!(r#"
            SELECT
                instrument_id,
                COUNT(*) as trade_count,
                SUM(volume) as total_volume,
                AVG(price) as avg_price,
                MIN(price) as min_price,
                MAX(price) as max_price
            FROM trades
            WHERE order_id IN (
                SELECT order_id FROM orders WHERE user_id = '{}'
            )
            GROUP BY instrument_id
            ORDER BY total_volume DESC
        "#, user_id);

        self.query(&sql)
    }

    /// é¢„å®šä¹‰æŸ¥è¯¢ï¼šå®æ—¶è¡Œæƒ…ç»Ÿè®¡
    pub fn market_stats(&mut self, instrument_id: &str, window_secs: i64)
        -> Result<DataFrame, String>
    {
        let now = chrono::Utc::now().timestamp();
        let start_time = now - window_secs;

        let sql = format!(r#"
            SELECT
                COUNT(*) as trade_count,
                SUM(volume) as volume,
                AVG(price) as vwap,
                MIN(price) as low,
                MAX(price) as high,
                FIRST(price) as open,
                LAST(price) as close
            FROM trades
            WHERE instrument_id = '{}'
              AND timestamp >= {}
        "#, instrument_id, start_time);

        self.query(&sql)
    }

    /// é¢„å®šä¹‰æŸ¥è¯¢ï¼šè´¦æˆ·ç›ˆäºåˆ†æ
    pub fn account_pnl(&mut self, user_id: &str) -> Result<DataFrame, String> {
        let sql = format!(r#"
            SELECT
                a.user_id,
                a.balance,
                a.available,
                a.frozen,
                a.margin,
                SUM(CASE WHEN o.direction = 0 THEN t.volume * t.price ELSE -t.volume * t.price END) as pnl
            FROM accounts a
            LEFT JOIN orders o ON a.user_id = o.user_id
            LEFT JOIN trades t ON o.order_id = t.order_id
            WHERE a.user_id = '{}'
            GROUP BY a.user_id, a.balance, a.available, a.frozen, a.margin
        "#, user_id);

        self.query(&sql)
    }
}
```

### 3. æµå¼æŸ¥è¯¢

```rust
// src/storage/query/streaming.rs

use polars::prelude::*;
use tokio::sync::mpsc;

pub struct StreamingQueryEngine {
    engine: Arc<RwLock<QueryEngine>>,
    update_interval: Duration,
}

impl StreamingQueryEngine {
    /// æµå¼æŸ¥è¯¢ï¼šå®æ—¶æ›´æ–°
    pub async fn stream_query(
        &self,
        sql: String,
    ) -> mpsc::UnboundedReceiver<DataFrame> {
        let (tx, rx) = mpsc::unbounded_channel();

        let engine = self.engine.clone();
        let interval = self.update_interval;

        tokio::spawn(async move {
            let mut ticker = tokio::time::interval(interval);

            loop {
                ticker.tick().await;

                let mut eng = engine.write();

                if let Ok(df) = eng.query(&sql) {
                    if tx.send(df).is_err() {
                        break;  // æ¥æ”¶æ–¹å·²å…³é—­
                    }
                }
            }
        });

        rx
    }

    /// æµå¼èšåˆï¼šå¢é‡è®¡ç®—
    pub async fn stream_aggregate(
        &self,
        table: &str,
        group_by: Vec<String>,
        aggregates: Vec<String>,
    ) -> mpsc::UnboundedReceiver<DataFrame> {
        // TODO: å®ç°å¢é‡èšåˆ
        let (tx, rx) = mpsc::unbounded_channel();
        rx
    }
}
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. é›¶æ‹·è´æŸ¥è¯¢

```rust
// Arrow2 é›¶æ‹·è´ä¼˜åŠ¿
// 1. mmap æ–‡ä»¶æ˜ å°„ï¼šç›´æ¥è®¿é—®ç£ç›˜æ•°æ®ï¼Œä¸éœ€è¦è¯»å…¥å†…å­˜
// 2. åˆ—å¼å­˜å‚¨ï¼šåªè¯»å–éœ€è¦çš„åˆ—ï¼Œå‡å°‘ I/O
// 3. SIMD å‘é‡åŒ–ï¼šæ‰¹é‡å¤„ç†ï¼Œ100x æ€§èƒ½æå‡

// ç¤ºä¾‹ï¼šè¯»å– Parquet æ–‡ä»¶ï¼ˆé›¶æ‹·è´ï¼‰
let reader = ParquetSSTableReader::open("orders.parquet")?;

// åªè¯»å–éœ€è¦çš„åˆ—
let projection = vec![0, 2, 5];  // order_id, instrument_id, price

// é›¶æ‹·è´è¯»å–
let chunks = reader.read_with_projection(&projection)?;
```

### 2. è°“è¯ä¸‹æ¨

```rust
// Parquet æ–‡ä»¶æ”¯æŒè°“è¯ä¸‹æ¨ï¼ˆPredicate Pushdownï¼‰
// åœ¨è¯»å–æ—¶å°±è¿‡æ»¤æ•°æ®ï¼Œå‡å°‘å†…å­˜å ç”¨

use arrow2::io::parquet::read::*;

// ç¤ºä¾‹ï¼šåªè¯»å– price > 100 çš„æ•°æ®
let filter = |row_group: &RowGroupMetaData| -> bool {
    // æ£€æŸ¥ row group çš„ç»Ÿè®¡ä¿¡æ¯
    if let Some(stats) = row_group.column(5).statistics() {
        if let Some(max) = stats.max_value {
            // å¦‚æœæœ€å¤§å€¼éƒ½ < 100ï¼Œè·³è¿‡è¿™ä¸ª row group
            return decode_float64(max) > 100.0;
        }
    }
    true
};

let reader = FileReader::try_new(file, Some(filter), None, None, None)?;
```

### 3. å‘é‡åŒ–æ‰§è¡Œ

```rust
// Polars è‡ªåŠ¨è¿›è¡Œå‘é‡åŒ–æ‰§è¡Œ

let df = self.query(r#"
    SELECT
        SUM(volume * price) as total_value
    FROM trades
    WHERE instrument_id = 'IX2401'
"#)?;

// Polars å†…éƒ¨ï¼š
// 1. å°† volume å’Œ price åˆ—è¯»å…¥ Arrow2 Array
// 2. ä½¿ç”¨ SIMD æŒ‡ä»¤æ‰¹é‡è®¡ç®— volume * price
// 3. ä½¿ç”¨ SIMD æŒ‡ä»¤æ‰¹é‡æ±‚å’Œ
// â†’ æ¯”é€è¡Œè®¡ç®—å¿« 100x
```

### 4. å¹¶è¡ŒæŸ¥è¯¢

```rust
// Polars è‡ªåŠ¨å¹¶è¡ŒåŒ–æŸ¥è¯¢

let df = LazyFrame::scan_parquet("trades.parquet")?
    .filter(col("timestamp").gt(start_time))
    .groupby([col("instrument_id")])
    .agg([
        col("volume").sum().alias("total_volume"),
        col("price").mean().alias("avg_price"),
    ])
    .collect()?;  // è‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œ

// Polars ä¼šï¼š
// 1. å¹¶è¡Œè¯»å–å¤šä¸ª Parquet æ–‡ä»¶
// 2. å¹¶è¡Œè¿‡æ»¤
// 3. å¹¶è¡Œåˆ†ç»„èšåˆ
// 4. åˆå¹¶ç»“æœ
```

---

## å®æ–½è®¡åˆ’

### Phase 8: Arrow2 æŸ¥è¯¢å¼•æ“ (2 å‘¨)

#### Week 1: Arrow2 é›†æˆ

- [ ] å®ç° ArrowMemTable
  - [ ] RecordBatch å­˜å‚¨
  - [ ] æŸ¥è¯¢æ¥å£
  - [ ] Polars è½¬æ¢

- [ ] å®ç° ParquetSSTableBuilder
  - [ ] Parquet å†™å…¥
  - [ ] å‹ç¼©é…ç½®ï¼ˆSnappyï¼‰
  - [ ] Schema å®šä¹‰

- [ ] å®ç° ParquetSSTableReader
  - [ ] Parquet è¯»å–
  - [ ] é›¶æ‹·è´ mmap
  - [ ] è°“è¯ä¸‹æ¨

#### Week 2: æŸ¥è¯¢å¼•æ“

- [ ] å®ç° HybridStorage
  - [ ] OLTP/OLAP åŒè·¯å¾„
  - [ ] å¼‚æ­¥è½¬æ¢

- [ ] å®ç° QueryEngine
  - [ ] Polars SQL é›†æˆ
  - [ ] è¡¨æ³¨å†Œ
  - [ ] é¢„å®šä¹‰æŸ¥è¯¢

- [ ] å®ç° StreamingQueryEngine
  - [ ] æµå¼æŸ¥è¯¢
  - [ ] å¢é‡èšåˆ

- [ ] æ€§èƒ½æµ‹è¯•
  - [ ] æŸ¥è¯¢å»¶è¿Ÿ
  - [ ] ååé‡
  - [ ] å†…å­˜å ç”¨

---

## æ€§èƒ½ç›®æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | å®ç°æ–¹å¼ |
|------|------|---------|
| **ç‚¹æŸ¥è¯¢å»¶è¿Ÿ** | P99 < 1ms | MemTable ç´¢å¼• |
| **æ‰«æåå** | > 1GB/s | é›¶æ‹·è´ mmap |
| **èšåˆæŸ¥è¯¢** | > 100M rows/s | SIMD å‘é‡åŒ– |
| **JOIN æ€§èƒ½** | > 10M rows/s | Hash Join |
| **å­˜å‚¨å‹ç¼©æ¯”** | 5-10x | Parquet åˆ—å¼å‹ç¼© |

---

## ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´ç¤ºä¾‹ï¼šOLTP + OLAP

```rust
use qaexchange::storage::{HybridStorage, QueryEngine};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 1. åˆ›å»ºæ··åˆå­˜å‚¨
    let storage = Arc::new(HybridStorage::new("/data"));

    // 2. OLTP å†™å…¥ï¼ˆä½å»¶è¿Ÿï¼‰
    storage.insert(
        order_id.as_bytes().to_vec(),
        order_data.to_rkyv_bytes()?,
    )?;

    // 3. OLAP æŸ¥è¯¢ï¼ˆé«˜ååï¼‰
    let mut engine = QueryEngine::new(storage.clone());

    // SQL æŸ¥è¯¢
    let stats = engine.query(r#"
        SELECT
            instrument_id,
            COUNT(*) as trade_count,
            SUM(volume) as total_volume,
            AVG(price) as avg_price
        FROM trades
        WHERE timestamp >= 1672531200
        GROUP BY instrument_id
        ORDER BY total_volume DESC
        LIMIT 10
    "#)?;

    println!("{:?}", stats);

    // é¢„å®šä¹‰æŸ¥è¯¢
    let user_stats = engine.user_trade_stats("user_001")?;
    println!("{:?}", user_stats);

    // æµå¼æŸ¥è¯¢
    let streaming = StreamingQueryEngine::new(engine.clone());
    let mut rx = streaming.stream_query(
        "SELECT * FROM trades WHERE timestamp > NOW() - 3600".to_string()
    ).await;

    while let Some(df) = rx.recv().await {
        println!("Real-time update: {:?}", df);
    }

    Ok(())
}
```

---

## ç›¸å…³é“¾æ¥

- [Arrow2 Documentation](https://jorgecarleitao.github.io/arrow2/)
- [Polars Documentation](https://pola-rs.github.io/polars/)
- [Parquet Format Specification](https://parquet.apache.org/docs/)

---

*æœ€åæ›´æ–°: 2025-10-03*
*ç»´æŠ¤è€…: @yutiansut*
