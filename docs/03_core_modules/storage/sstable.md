# SSTable (Sorted String Table) æ ¼å¼

## ğŸ“– æ¦‚è¿°

SSTable (Sorted String Table) æ˜¯ QAExchange-RS å­˜å‚¨ç³»ç»Ÿä¸­ MemTable çš„æŒä¹…åŒ–æ ¼å¼ã€‚å½“ MemTable è¾¾åˆ°å¤§å°é˜ˆå€¼æ—¶ï¼Œæ•°æ®ä¼šè¢« flush åˆ°ç£ç›˜ä¸Šçš„ SSTable æ–‡ä»¶ä¸­ï¼Œæä¾›é«˜æ•ˆçš„ç£ç›˜å­˜å‚¨å’Œé›¶æ‹·è´è¯»å–èƒ½åŠ›ã€‚

## ğŸ¯ è®¾è®¡ç›®æ ‡

- **æŒä¹…åŒ–**: MemTable æ•°æ®çš„æ°¸ä¹…å­˜å‚¨
- **é›¶æ‹·è´è¯»å–**: ä½¿ç”¨ mmap é¿å…æ•°æ®æ‹·è´ (OLTP)
- **é«˜å‹ç¼©ç‡**: åˆ—å¼å­˜å‚¨å‡å°‘ç£ç›˜å ç”¨ (OLAP)
- **å¿«é€ŸæŸ¥æ‰¾**: Bloom Filter + ç´¢å¼•åŠ é€Ÿ
- **é¡ºåºå†™å…¥**: LSM-Tree æ¶æ„ï¼Œå†™å…¥æ€§èƒ½ä¼˜ç§€

## ğŸ—ï¸ åŒæ ¼å¼æ¶æ„

QAExchange-RS å®ç°äº† **OLTP** å’Œ **OLAP** åŒ SSTable ä½“ç³»ï¼š

### 1. OLTP SSTable (rkyv æ ¼å¼)

#### è®¾è®¡ç†å¿µ

- **ç›®æ ‡åœºæ™¯**: ä½å»¶è¿Ÿç‚¹æŸ¥è¯¢ã€å°èŒƒå›´æ‰«æ
- **åºåˆ—åŒ–æ ¼å¼**: rkyv (zero-copy)
- **è¯»å–æ–¹å¼**: mmap å†…å­˜æ˜ å°„
- **å…¸å‹å»¶è¿Ÿ**: P99 < 20Î¼s

#### æ–‡ä»¶æ ¼å¼

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Header (32 bytes)                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Magic Number: 0x53535442 ("SSTB")                     â”‚  â”‚
â”‚  â”‚ Version: u32                                           â”‚  â”‚
â”‚  â”‚ Created At: i64 (timestamp)                            â”‚  â”‚
â”‚  â”‚ Number of Entries: u64                                 â”‚  â”‚
â”‚  â”‚ Bloom Filter Offset: u64                               â”‚  â”‚
â”‚  â”‚ Index Offset: u64                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Bloom Filter (å¯é€‰, ~1KB - 10KB)                           â”‚
â”‚  - Bit array size: computed from entry count                â”‚
â”‚  - Number of hash functions: 7 (optimal for 1% FP rate)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Blocks (multiple, 4KB - 64KB each)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Block 1:                                               â”‚  â”‚
â”‚  â”‚   Entry 1: [Key Length: u32] [Key: bytes]             â”‚  â”‚
â”‚  â”‚            [Value Length: u32] [Value: rkyv bytes]    â”‚  â”‚
â”‚  â”‚   Entry 2: ...                                         â”‚  â”‚
â”‚  â”‚   ...                                                  â”‚  â”‚
â”‚  â”‚ Block 2:                                               â”‚  â”‚
â”‚  â”‚   Entry N: ...                                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Index Block                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Sparse Index (æ¯ä¸ª Block ä¸€æ¡ç´¢å¼•)                     â”‚  â”‚
â”‚  â”‚   [First Key: bytes] â†’ [Block Offset: u64]            â”‚  â”‚
â”‚  â”‚   [First Key: bytes] â†’ [Block Offset: u64]            â”‚  â”‚
â”‚  â”‚   ...                                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Footer (64 bytes)                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Index CRC32: u32                                       â”‚  â”‚
â”‚  â”‚ Data CRC32: u32                                        â”‚  â”‚
â”‚  â”‚ Total File Size: u64                                   â”‚  â”‚
â”‚  â”‚ Padding: [u8; 48]                                      â”‚  â”‚
â”‚  â”‚ Magic Number: 0x53535442 (validation)                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### æ ¸å¿ƒå®ç°

```rust
// src/storage/sstable/oltp_rkyv.rs

use rkyv::{Archive, Serialize, Deserialize};
use memmap2::Mmap;

/// OLTP SSTable å†™å…¥å™¨
pub struct OltpSstableWriter {
    /// è¾“å‡ºæ–‡ä»¶
    file: File,

    /// å½“å‰åç§»é‡
    current_offset: u64,

    /// æ•°æ®å—ç¼“å†²
    block_buffer: Vec<u8>,

    /// å—å¤§å°é˜ˆå€¼ (é»˜è®¤ 64KB)
    block_size_threshold: usize,

    /// ç¨€ç–ç´¢å¼• (æ¯ä¸ªå—çš„ç¬¬ä¸€ä¸ª key)
    sparse_index: BTreeMap<Vec<u8>, u64>,

    /// Bloom Filter æ„å»ºå™¨
    bloom_builder: Option<BloomFilterBuilder>,

    /// é…ç½®
    config: SstableConfig,
}

impl OltpSstableWriter {
    /// åˆ›å»ºæ–°çš„ SSTable å†™å…¥å™¨
    pub fn new(path: PathBuf, config: SstableConfig) -> Result<Self> {
        let mut file = File::create(&path)?;

        // é¢„ç•™ Header ç©ºé—´
        file.write_all(&[0u8; 32])?;

        Ok(Self {
            file,
            current_offset: 32,
            block_buffer: Vec::with_capacity(config.block_size),
            block_size_threshold: config.block_size,
            sparse_index: BTreeMap::new(),
            bloom_builder: if config.enable_bloom_filter {
                Some(BloomFilterBuilder::new(config.expected_entries))
            } else {
                None
            },
            config,
        })
    }

    /// å†™å…¥é”®å€¼å¯¹
    pub fn write(&mut self, key: &[u8], value: &[u8]) -> Result<()> {
        // è®°å½•å—çš„ç¬¬ä¸€ä¸ª key
        if self.block_buffer.is_empty() {
            self.sparse_index.insert(key.to_vec(), self.current_offset);
        }

        // æ·»åŠ åˆ° Bloom Filter
        if let Some(ref mut bloom) = self.bloom_builder {
            bloom.insert(key);
        }

        // å†™å…¥åˆ°å—ç¼“å†²
        self.block_buffer.write_u32::<LittleEndian>(key.len() as u32)?;
        self.block_buffer.write_all(key)?;
        self.block_buffer.write_u32::<LittleEndian>(value.len() as u32)?;
        self.block_buffer.write_all(value)?;

        // æ£€æŸ¥æ˜¯å¦éœ€è¦ flush å—
        if self.block_buffer.len() >= self.block_size_threshold {
            self.flush_block()?;
        }

        Ok(())
    }

    /// Flush å½“å‰æ•°æ®å—åˆ°æ–‡ä»¶
    fn flush_block(&mut self) -> Result<()> {
        if self.block_buffer.is_empty() {
            return Ok(());
        }

        // å†™å…¥å—æ•°æ®
        self.file.write_all(&self.block_buffer)?;
        self.current_offset += self.block_buffer.len() as u64;

        // æ¸…ç©ºç¼“å†²
        self.block_buffer.clear();

        Ok(())
    }

    /// å®Œæˆå†™å…¥ï¼Œå†™å…¥ Bloom Filterã€ç´¢å¼•å’Œ Footer
    pub fn finish(mut self) -> Result<SstableMetadata> {
        // 1. Flush æœ€åä¸€ä¸ªå—
        self.flush_block()?;

        let bloom_offset = self.current_offset;

        // 2. å†™å…¥ Bloom Filter
        let bloom_size = if let Some(bloom) = self.bloom_builder {
            let bloom_bytes = bloom.build().to_bytes();
            self.file.write_all(&bloom_bytes)?;
            bloom_bytes.len() as u64
        } else {
            0
        };

        self.current_offset += bloom_size;
        let index_offset = self.current_offset;

        // 3. å†™å…¥ç¨€ç–ç´¢å¼•
        let index_bytes = rkyv::to_bytes::<_, 256>(&self.sparse_index)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, e))?;
        self.file.write_all(&index_bytes)?;
        self.current_offset += index_bytes.len() as u64;

        // 4. è®¡ç®— CRC
        let data_crc = self.compute_data_crc()?;
        let index_crc = crc32fast::hash(&index_bytes);

        // 5. å†™å…¥ Footer
        self.file.write_u32::<LittleEndian>(index_crc)?;
        self.file.write_u32::<LittleEndian>(data_crc)?;
        self.file.write_u64::<LittleEndian>(self.current_offset + 64)?;
        self.file.write_all(&[0u8; 48])?; // padding
        self.file.write_u32::<LittleEndian>(0x53535442)?; // magic

        // 6. æ›´æ–° Header
        self.file.seek(SeekFrom::Start(0))?;
        self.write_header(bloom_offset, index_offset)?;

        // 7. Sync to disk
        self.file.sync_all()?;

        Ok(SstableMetadata {
            num_entries: self.sparse_index.len() as u64,
            file_size: self.current_offset + 64,
            bloom_filter_size: bloom_size,
            index_size: index_bytes.len() as u64,
        })
    }

    fn write_header(&mut self, bloom_offset: u64, index_offset: u64) -> Result<()> {
        self.file.write_u32::<LittleEndian>(0x53535442)?; // magic
        self.file.write_u32::<LittleEndian>(1)?; // version
        self.file.write_i64::<LittleEndian>(chrono::Utc::now().timestamp())?;
        self.file.write_u64::<LittleEndian>(self.sparse_index.len() as u64)?;
        self.file.write_u64::<LittleEndian>(bloom_offset)?;
        self.file.write_u64::<LittleEndian>(index_offset)?;
        Ok(())
    }

    fn compute_data_crc(&mut self) -> Result<u32> {
        self.file.seek(SeekFrom::Start(32))?;
        let mut hasher = crc32fast::Hasher::new();
        let mut buffer = vec![0u8; 8192];

        loop {
            let n = self.file.read(&mut buffer)?;
            if n == 0 {
                break;
            }
            hasher.update(&buffer[..n]);
        }

        Ok(hasher.finalize())
    }
}

/// OLTP SSTable è¯»å–å™¨ (mmap é›¶æ‹·è´)
pub struct OltpSstableReader {
    /// å†…å­˜æ˜ å°„æ–‡ä»¶
    mmap: Mmap,

    /// ç¨€ç–ç´¢å¼• (ååºåˆ—åŒ–åçš„)
    sparse_index: BTreeMap<Vec<u8>, u64>,

    /// Bloom Filter
    bloom_filter: Option<BloomFilter>,

    /// Header ä¿¡æ¯
    header: SstableHeader,
}

impl OltpSstableReader {
    /// æ‰“å¼€ SSTable æ–‡ä»¶
    pub fn open(path: &Path) -> Result<Self> {
        let file = File::open(path)?;
        let mmap = unsafe { Mmap::map(&file)? };

        // è¯»å–å¹¶éªŒè¯ Header
        let header = Self::read_header(&mmap)?;

        // è¯»å– Bloom Filter
        let bloom_filter = if header.bloom_offset > 0 {
            let bloom_bytes = &mmap[header.bloom_offset as usize..header.index_offset as usize];
            Some(BloomFilter::from_bytes(bloom_bytes)?)
        } else {
            None
        };

        // è¯»å–ç¨€ç–ç´¢å¼•
        let index_bytes = &mmap[header.index_offset as usize..];
        let sparse_index = rkyv::from_bytes::<BTreeMap<Vec<u8>, u64>>(index_bytes)
            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))?;

        Ok(Self {
            mmap,
            sparse_index,
            bloom_filter,
            header,
        })
    }

    /// ç‚¹æŸ¥è¯¢ (é›¶æ‹·è´)
    pub fn get(&self, key: &[u8]) -> Result<Option<&[u8]>> {
        // 1. Bloom Filter å¿«é€Ÿè¿‡æ»¤
        if let Some(ref bloom) = self.bloom_filter {
            if !bloom.contains(key) {
                return Ok(None); // ä¸€å®šä¸å­˜åœ¨
            }
        }

        // 2. å®šä½æ•°æ®å—
        let block_offset = self.find_block(key)?;
        if block_offset.is_none() {
            return Ok(None);
        }

        let block_start = block_offset.unwrap() as usize;

        // 3. åœ¨å—å†…äºŒåˆ†æŸ¥æ‰¾
        self.search_in_block(block_start, key)
    }

    /// èŒƒå›´æ‰«æ
    pub fn scan(&self, start: &[u8], end: &[u8]) -> Result<Vec<(&[u8], &[u8])>> {
        let mut results = Vec::new();

        // å®šä½èµ·å§‹å—
        let start_block = self.find_block(start)?.unwrap_or(32);

        // éå†æ‰€æœ‰å¯èƒ½çš„å—
        for (block_key, block_offset) in self.sparse_index.range(start.to_vec()..) {
            if block_key.as_slice() >= end {
                break;
            }

            // æ‰«æå—å†…æ•°æ®
            let block_results = self.scan_block(*block_offset as usize, start, end)?;
            results.extend(block_results);
        }

        Ok(results)
    }

    fn find_block(&self, key: &[u8]) -> Result<Option<u64>> {
        // ä½¿ç”¨ç¨€ç–ç´¢å¼•æ‰¾åˆ°åŒ…å« key çš„å—
        let mut iter = self.sparse_index.range(..=key.to_vec());
        Ok(iter.next_back().map(|(_, offset)| *offset))
    }

    fn search_in_block(&self, block_start: usize, target_key: &[u8]) -> Result<Option<&[u8]>> {
        let mut cursor = block_start;

        loop {
            // æ£€æŸ¥æ˜¯å¦è¶…å‡ºå—è¾¹ç•Œ
            if cursor >= self.mmap.len() {
                return Ok(None);
            }

            // è¯»å– key
            let key_len = u32::from_le_bytes([
                self.mmap[cursor],
                self.mmap[cursor + 1],
                self.mmap[cursor + 2],
                self.mmap[cursor + 3],
            ]) as usize;
            cursor += 4;

            let key = &self.mmap[cursor..cursor + key_len];
            cursor += key_len;

            // è¯»å– value
            let value_len = u32::from_le_bytes([
                self.mmap[cursor],
                self.mmap[cursor + 1],
                self.mmap[cursor + 2],
                self.mmap[cursor + 3],
            ]) as usize;
            cursor += 4;

            let value = &self.mmap[cursor..cursor + value_len];
            cursor += value_len;

            // æ¯”è¾ƒ key
            match key.cmp(target_key) {
                Ordering::Equal => return Ok(Some(value)), // æ‰¾åˆ°ï¼é›¶æ‹·è´è¿”å›
                Ordering::Greater => return Ok(None),      // å·²è¶…è¿‡ï¼Œä¸å­˜åœ¨
                Ordering::Less => continue,                // ç»§ç»­æŸ¥æ‰¾
            }
        }
    }

    fn scan_block(&self, block_start: usize, start: &[u8], end: &[u8])
        -> Result<Vec<(&[u8], &[u8])>>
    {
        let mut results = Vec::new();
        let mut cursor = block_start;

        loop {
            if cursor >= self.mmap.len() {
                break;
            }

            // è¯»å– entry
            let key_len = u32::from_le_bytes([
                self.mmap[cursor],
                self.mmap[cursor + 1],
                self.mmap[cursor + 2],
                self.mmap[cursor + 3],
            ]) as usize;
            cursor += 4;

            let key = &self.mmap[cursor..cursor + key_len];
            cursor += key_len;

            let value_len = u32::from_le_bytes([
                self.mmap[cursor],
                self.mmap[cursor + 1],
                self.mmap[cursor + 2],
                self.mmap[cursor + 3],
            ]) as usize;
            cursor += 4;

            let value = &self.mmap[cursor..cursor + value_len];
            cursor += value_len;

            // æ£€æŸ¥èŒƒå›´
            if key >= start && key < end {
                results.push((key, value));
            } else if key >= end {
                break;
            }
        }

        Ok(results)
    }

    fn read_header(mmap: &Mmap) -> Result<SstableHeader> {
        let mut cursor = 0;

        let magic = u32::from_le_bytes([mmap[0], mmap[1], mmap[2], mmap[3]]);
        if magic != 0x53535442 {
            return Err(io::Error::new(io::ErrorKind::InvalidData, "Invalid magic number"));
        }
        cursor += 4;

        let version = u32::from_le_bytes([mmap[4], mmap[5], mmap[6], mmap[7]]);
        cursor += 4;

        let created_at = i64::from_le_bytes([
            mmap[8], mmap[9], mmap[10], mmap[11],
            mmap[12], mmap[13], mmap[14], mmap[15],
        ]);
        cursor += 8;

        let num_entries = u64::from_le_bytes([
            mmap[16], mmap[17], mmap[18], mmap[19],
            mmap[20], mmap[21], mmap[22], mmap[23],
        ]);
        cursor += 8;

        let bloom_offset = u64::from_le_bytes([
            mmap[24], mmap[25], mmap[26], mmap[27],
            mmap[28], mmap[29], mmap[30], mmap[31],
        ]);
        cursor += 8;

        let index_offset = u64::from_le_bytes([
            mmap[32], mmap[33], mmap[34], mmap[35],
            mmap[36], mmap[37], mmap[38], mmap[39],
        ]);

        Ok(SstableHeader {
            magic,
            version,
            created_at,
            num_entries,
            bloom_offset,
            index_offset,
        })
    }
}

#[derive(Debug, Clone)]
pub struct SstableHeader {
    pub magic: u32,
    pub version: u32,
    pub created_at: i64,
    pub num_entries: u64,
    pub bloom_offset: u64,
    pub index_offset: u64,
}

#[derive(Debug, Clone)]
pub struct SstableMetadata {
    pub num_entries: u64,
    pub file_size: u64,
    pub bloom_filter_size: u64,
    pub index_size: u64,
}

#[derive(Debug, Clone)]
pub struct SstableConfig {
    /// æ•°æ®å—å¤§å° (é»˜è®¤ 64KB)
    pub block_size: usize,

    /// æ˜¯å¦å¯ç”¨ Bloom Filter
    pub enable_bloom_filter: bool,

    /// é¢„æœŸæ¡ç›®æ•° (ç”¨äº Bloom Filter å¤§å°è®¡ç®—)
    pub expected_entries: usize,
}

impl Default for SstableConfig {
    fn default() -> Self {
        Self {
            block_size: 64 * 1024,
            enable_bloom_filter: true,
            expected_entries: 10000,
        }
    }
}
```

#### æ€§èƒ½ç‰¹æ€§

**å†™å…¥æ€§èƒ½**:
- æ‰¹é‡å†™å…¥: > 100K entries/sec
- å—ç¼“å†²: å‡å°‘ç³»ç»Ÿè°ƒç”¨
- é¡ºåºå†™å…¥: SSD/HDD å‹å¥½

**è¯»å–æ€§èƒ½** (Phase 7 ä¼˜åŒ–å):
- ç‚¹æŸ¥è¯¢: **P99 < 20Î¼s** (mmap)
- Bloom Filter: ~100ns è¿‡æ»¤
- é›¶æ‹·è´: ç›´æ¥è¿”å› mmap åˆ‡ç‰‡

### 2. OLAP SSTable (Parquet æ ¼å¼)

#### è®¾è®¡ç†å¿µ

- **ç›®æ ‡åœºæ™¯**: æ‰¹é‡æ‰«æã€èšåˆåˆ†æã€BI æŠ¥è¡¨
- **æ–‡ä»¶æ ¼å¼**: Apache Parquet
- **å‹ç¼©ç®—æ³•**: Snappy / Zstd
- **å…¸å‹åå**: > 1.5 GB/s

#### æ ¸å¿ƒå®ç°

```rust
// src/storage/sstable/olap_parquet.rs

use arrow2::array::*;
use arrow2::chunk::Chunk;
use arrow2::datatypes::*;
use arrow2::io::parquet::write::*;

/// OLAP SSTable å†™å…¥å™¨
pub struct OlapSstableWriter {
    /// è¾“å‡ºè·¯å¾„
    path: PathBuf,

    /// Arrow Schema
    schema: Schema,

    /// åˆ—æ•°æ®ç¼“å†²
    columns: Vec<Vec<Box<dyn Array>>>,

    /// å½“å‰è¡Œæ•°
    row_count: usize,

    /// Row Group å¤§å° (é»˜è®¤ 100K è¡Œ)
    row_group_size: usize,
}

impl OlapSstableWriter {
    pub fn new(path: PathBuf, schema: Schema) -> Result<Self> {
        Ok(Self {
            path,
            schema,
            columns: vec![Vec::new(); schema.fields.len()],
            row_count: 0,
            row_group_size: 100_000,
        })
    }

    /// å†™å…¥ RecordBatch
    pub fn write_batch(&mut self, batch: Chunk<Box<dyn Array>>) -> Result<()> {
        for (i, column) in batch.columns().iter().enumerate() {
            self.columns[i].push(column.clone());
        }

        self.row_count += batch.len();
        Ok(())
    }

    /// å®Œæˆå†™å…¥
    pub fn finish(self) -> Result<()> {
        let file = File::create(&self.path)?;

        // Parquet å†™å…¥é…ç½®
        let options = WriteOptions {
            write_statistics: true,
            compression: CompressionOptions::Snappy, // æˆ– Zstd
            version: Version::V2,
            data_pagesize_limit: Some(64 * 1024), // 64KB
        };

        // æ„å»º Row Groups
        let row_groups = self.build_row_groups()?;

        // å†™å…¥ Parquet
        let mut writer = FileWriter::try_new(file, self.schema, options)?;

        for row_group in row_groups {
            writer.write(row_group)?;
        }

        writer.end(None)?;

        Ok(())
    }

    fn build_row_groups(&self) -> Result<Vec<RowGroup>> {
        // å°†åˆ—æ•°æ®åˆ‡åˆ†ä¸ºå¤šä¸ª Row Group
        let num_row_groups = (self.row_count + self.row_group_size - 1) / self.row_group_size;
        let mut row_groups = Vec::with_capacity(num_row_groups);

        for i in 0..num_row_groups {
            let start_row = i * self.row_group_size;
            let end_row = ((i + 1) * self.row_group_size).min(self.row_count);

            // åˆ‡ç‰‡åˆ—æ•°æ®
            let mut row_group_columns = Vec::new();
            for col_arrays in &self.columns {
                let sliced = self.slice_arrays(col_arrays, start_row, end_row)?;
                row_group_columns.push(sliced);
            }

            row_groups.push(RowGroup {
                columns: row_group_columns,
                num_rows: end_row - start_row,
            });
        }

        Ok(row_groups)
    }

    fn slice_arrays(&self, arrays: &[Box<dyn Array>], start: usize, end: usize)
        -> Result<Box<dyn Array>>
    {
        // åˆå¹¶å¹¶åˆ‡ç‰‡æ•°ç»„
        let concatenated = concatenate(arrays)?;
        Ok(concatenated.sliced(start, end - start))
    }
}

/// OLAP SSTable è¯»å–å™¨
pub struct OlapSstableReader {
    path: PathBuf,
    schema: Schema,
    metadata: FileMetadata,
}

impl OlapSstableReader {
    pub fn open(path: &Path) -> Result<Self> {
        let file = File::open(path)?;
        let metadata = read_metadata(&mut BufReader::new(&file))?;
        let schema = infer_schema(&metadata)?;

        Ok(Self {
            path: path.to_path_buf(),
            schema,
            metadata,
        })
    }

    /// è¯»å–æ‰€æœ‰æ•°æ®
    pub fn read_all(&self) -> Result<Chunk<Box<dyn Array>>> {
        let file = File::open(&self.path)?;
        let reader = FileReader::new(file, self.metadata.row_groups.clone(), self.schema.clone(), None, None, None);

        let mut chunks = Vec::new();
        for maybe_chunk in reader {
            chunks.push(maybe_chunk?);
        }

        // åˆå¹¶æ‰€æœ‰ chunks
        concatenate_chunks(&chunks)
    }

    /// è¯»å–æŒ‡å®šåˆ—
    pub fn read_columns(&self, column_names: &[&str]) -> Result<Chunk<Box<dyn Array>>> {
        let column_indices: Vec<_> = column_names
            .iter()
            .map(|name| self.schema.fields.iter().position(|f| f.name == *name))
            .collect::<Option<Vec<_>>>()
            .ok_or_else(|| io::Error::new(io::ErrorKind::NotFound, "Column not found"))?;

        let file = File::open(&self.path)?;
        let reader = FileReader::new(
            file,
            self.metadata.row_groups.clone(),
            self.schema.clone(),
            Some(column_indices),
            None,
            None
        );

        let mut chunks = Vec::new();
        for maybe_chunk in reader {
            chunks.push(maybe_chunk?);
        }

        concatenate_chunks(&chunks)
    }

    /// å¸¦è°“è¯ä¸‹æ¨çš„è¯»å–
    pub fn read_with_predicate<F>(&self, predicate: F) -> Result<Chunk<Box<dyn Array>>>
    where
        F: Fn(&Chunk<Box<dyn Array>>) -> Result<BooleanArray>,
    {
        let file = File::open(&self.path)?;
        let reader = FileReader::new(file, self.metadata.row_groups.clone(), self.schema.clone(), None, None, None);

        let mut filtered_chunks = Vec::new();

        for maybe_chunk in reader {
            let chunk = maybe_chunk?;
            let mask = predicate(&chunk)?;
            let filtered = filter_chunk(&chunk, &mask)?;
            filtered_chunks.push(filtered);
        }

        concatenate_chunks(&filtered_chunks)
    }
}

fn concatenate_chunks(chunks: &[Chunk<Box<dyn Array>>]) -> Result<Chunk<Box<dyn Array>>> {
    if chunks.is_empty() {
        return Err(io::Error::new(io::ErrorKind::InvalidInput, "No chunks to concatenate"));
    }

    let num_columns = chunks[0].columns().len();
    let mut result_columns = Vec::with_capacity(num_columns);

    for col_idx in 0..num_columns {
        let column_arrays: Vec<_> = chunks.iter()
            .map(|chunk| chunk.columns()[col_idx].as_ref())
            .collect();

        let concatenated = concatenate(&column_arrays)?;
        result_columns.push(concatenated);
    }

    Ok(Chunk::new(result_columns))
}

fn filter_chunk(chunk: &Chunk<Box<dyn Array>>, mask: &BooleanArray) -> Result<Chunk<Box<dyn Array>>> {
    let filtered_columns: Vec<_> = chunk.columns()
        .iter()
        .map(|col| filter(col.as_ref(), mask))
        .collect::<Result<_, _>>()?;

    Ok(Chunk::new(filtered_columns))
}
```

#### æ€§èƒ½ç‰¹æ€§

**å‹ç¼©æ•ˆæœ**:
- Snappy: 2-4x å‹ç¼©ç‡, ä½ CPU å¼€é”€
- Zstd: 5-10x å‹ç¼©ç‡, é«˜ CPU å¼€é”€

**æ‰«ææ€§èƒ½**:
- åˆ—å¼æ‰«æ: > 10M rows/sec
- å…¨è¡¨æ‰«æ: > 1.5 GB/s
- è°“è¯ä¸‹æ¨: è·³è¿‡ä¸åŒ¹é…çš„ Row Group

## ğŸŒ¸ Bloom Filter

### è®¾è®¡

```rust
// src/storage/sstable/bloom.rs

use bit_vec::BitVec;

pub struct BloomFilter {
    /// ä½æ•°ç»„
    bits: BitVec,

    /// å“ˆå¸Œå‡½æ•°æ•°é‡
    num_hashes: usize,

    /// ä½æ•°ç»„å¤§å°
    num_bits: usize,
}

impl BloomFilter {
    /// åˆ›å»º Bloom Filter
    /// - `expected_items`: é¢„æœŸå…ƒç´ æ•°é‡
    /// - `false_positive_rate`: å‡é˜³ç‡ (é»˜è®¤ 0.01 = 1%)
    pub fn new(expected_items: usize, false_positive_rate: f64) -> Self {
        // è®¡ç®—æœ€ä¼˜å‚æ•°
        let num_bits = Self::optimal_num_bits(expected_items, false_positive_rate);
        let num_hashes = Self::optimal_num_hashes(num_bits, expected_items);

        Self {
            bits: BitVec::from_elem(num_bits, false),
            num_hashes,
            num_bits,
        }
    }

    /// æ’å…¥å…ƒç´ 
    pub fn insert(&mut self, key: &[u8]) {
        for i in 0..self.num_hashes {
            let hash = self.hash(key, i);
            let bit_index = (hash % self.num_bits as u64) as usize;
            self.bits.set(bit_index, true);
        }
    }

    /// æ£€æŸ¥å…ƒç´ æ˜¯å¦å¯èƒ½å­˜åœ¨
    pub fn contains(&self, key: &[u8]) -> bool {
        for i in 0..self.num_hashes {
            let hash = self.hash(key, i);
            let bit_index = (hash % self.num_bits as u64) as usize;
            if !self.bits.get(bit_index).unwrap_or(false) {
                return false; // ä¸€å®šä¸å­˜åœ¨
            }
        }
        true // å¯èƒ½å­˜åœ¨
    }

    /// å“ˆå¸Œå‡½æ•° (double hashing)
    fn hash(&self, key: &[u8], i: usize) -> u64 {
        let hash1 = seahash::hash(key);
        let hash2 = seahash::hash(&hash1.to_le_bytes());
        hash1.wrapping_add(i as u64 * hash2)
    }

    /// è®¡ç®—æœ€ä¼˜ä½æ•°é‡
    fn optimal_num_bits(n: usize, p: f64) -> usize {
        let ln2 = std::f64::consts::LN_2;
        (-(n as f64) * p.ln() / (ln2 * ln2)).ceil() as usize
    }

    /// è®¡ç®—æœ€ä¼˜å“ˆå¸Œå‡½æ•°æ•°é‡
    fn optimal_num_hashes(m: usize, n: usize) -> usize {
        ((m as f64 / n as f64) * std::f64::consts::LN_2).ceil() as usize
    }

    /// åºåˆ—åŒ–
    pub fn to_bytes(&self) -> Vec<u8> {
        let mut bytes = Vec::new();
        bytes.write_u64::<LittleEndian>(self.num_bits as u64).unwrap();
        bytes.write_u64::<LittleEndian>(self.num_hashes as u64).unwrap();
        bytes.extend_from_slice(&self.bits.to_bytes());
        bytes
    }

    /// ååºåˆ—åŒ–
    pub fn from_bytes(bytes: &[u8]) -> Result<Self> {
        let mut cursor = Cursor::new(bytes);
        let num_bits = cursor.read_u64::<LittleEndian>()? as usize;
        let num_hashes = cursor.read_u64::<LittleEndian>()? as usize;

        let mut bit_bytes = Vec::new();
        cursor.read_to_end(&mut bit_bytes)?;
        let bits = BitVec::from_bytes(&bit_bytes);

        Ok(Self {
            bits,
            num_hashes,
            num_bits,
        })
    }
}
```

### æ€§èƒ½åˆ†æ

**æŸ¥æ‰¾å»¶è¿Ÿ**: ~100ns (7 æ¬¡å“ˆå¸Œ)

**å‡é˜³ç‡**: 1% (å¯é…ç½®)
- 10,000 æ¡ç›®: ~12 KB
- 100,000 æ¡ç›®: ~120 KB
- 1,000,000 æ¡ç›®: ~1.2 MB

**æ”¶ç›Š**:
- é¿å…æ— æ•ˆç£ç›˜ I/O
- åŠ é€Ÿ 99% çš„è´ŸæŸ¥è¯¢

## ğŸ“Š Compaction

### Leveled Compaction ç­–ç•¥

```
Level 0:  [SST1] [SST2] [SST3] [SST4]  â† å¯èƒ½æœ‰é‡å 
            â†“ Compaction
Level 1:  [SST5â”€â”€â”€â”€â”€â”€SST6â”€â”€â”€â”€â”€â”€SST7]   â† æ— é‡å , 10 MB/file
            â†“ Compaction
Level 2:  [SST8â”€â”€â”€â”€â”€â”€SST9â”€â”€â”€â”€â”€â”€SST10â”€â”€â”€â”€â”€SST11]  â† 100 MB/file
            â†“ Compaction
Level 3:  [SST12â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€SST13â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€SST14]  â† 1 GB/file
```

### è§¦å‘æ¡ä»¶

```rust
pub struct CompactionTrigger {
    /// Level 0 æ–‡ä»¶æ•°é˜ˆå€¼
    l0_file_threshold: usize,  // é»˜è®¤ 4

    /// å„å±‚å¤§å°é˜ˆå€¼
    level_size_multiplier: usize,  // é»˜è®¤ 10
}

impl CompactionTrigger {
    pub fn should_compact(&self, level: usize, file_count: usize, total_size: u64) -> bool {
        match level {
            0 => file_count >= self.l0_file_threshold,
            n => total_size >= self.level_target_size(n),
        }
    }

    fn level_target_size(&self, level: usize) -> u64 {
        10 * 1024 * 1024 * (self.level_size_multiplier.pow(level as u32 - 1)) as u64
    }
}
```

## ğŸ› ï¸ é…ç½®ç¤ºä¾‹

```toml
# config/storage.toml
[sstable.oltp]
block_size_kb = 64
enable_bloom_filter = true
expected_entries_per_file = 100000
bloom_false_positive_rate = 0.01

[sstable.olap]
row_group_size = 100000
compression = "snappy"  # or "zstd", "none"
data_page_size_kb = 64

[compaction]
l0_file_threshold = 4
level_size_multiplier = 10
max_background_compactions = 2
```

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### OLTP SSTable

| æ“ä½œ | æ—  Bloom Filter | æœ‰ Bloom Filter | ä¼˜åŒ– (%) |
|------|----------------|----------------|---------|
| ç‚¹æŸ¥è¯¢ (å­˜åœ¨) | 45 Î¼s | 22 Î¼s | +52% |
| ç‚¹æŸ¥è¯¢ (ä¸å­˜åœ¨) | 42 Î¼s | 0.1 Î¼s | +99.8% |
| èŒƒå›´æ‰«æ (1K) | 850 Î¼s | 850 Î¼s | 0% |

### OLAP SSTable

| æ“ä½œ | Snappy | Zstd | æ— å‹ç¼© |
|------|--------|------|--------|
| å†™å…¥é€Ÿåº¦ | 1.2 GB/s | 800 MB/s | 2 GB/s |
| è¯»å–é€Ÿåº¦ | 1.5 GB/s | 1.3 GB/s | 3 GB/s |
| å‹ç¼©ç‡ | 3.5x | 8x | 1x |
| ç£ç›˜å ç”¨ | 286 MB | 125 MB | 1 GB |

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„ SSTable ç±»å‹

```rust
// OLTP: éœ€è¦ä½å»¶è¿Ÿç‚¹æŸ¥è¯¢
if use_case.requires_low_latency() {
    use_oltp_sstable();
}

// OLAP: éœ€è¦æ‰¹é‡æ‰«æå’Œåˆ†æ
if use_case.is_analytical() {
    use_olap_sstable();
}
```

### 2. Bloom Filter å‚æ•°è°ƒä¼˜

```rust
// é«˜å‡é˜³ç‡ â†’ å°å†…å­˜å ç”¨,ä½†æ›´å¤šç£ç›˜ I/O
let bloom = BloomFilter::new(entries, 0.05); // 5% FP rate

// ä½å‡é˜³ç‡ â†’ å¤§å†…å­˜å ç”¨,ä½†å°‘ç£ç›˜ I/O
let bloom = BloomFilter::new(entries, 0.001); // 0.1% FP rate
```

### 3. å‹ç¼©ç®—æ³•é€‰æ‹©

```rust
// Snappy: å¹³è¡¡æ€§èƒ½å’Œå‹ç¼©ç‡
config.compression = CompressionOptions::Snappy;

// Zstd: é«˜å‹ç¼©ç‡,é€‚åˆå†·æ•°æ®
config.compression = CompressionOptions::Zstd;

// æ— å‹ç¼©: æœ€é«˜æ€§èƒ½,ä½†ç£ç›˜å ç”¨å¤§
config.compression = CompressionOptions::None;
```

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: SSTable è¯»å–ç¼“æ…¢

**ç—‡çŠ¶**: P99 å»¶è¿Ÿ > 100Î¼s

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥ Bloom Filter æ˜¯å¦å¯ç”¨
2. æ£€æŸ¥ mmap æ˜¯å¦ç”Ÿæ•ˆ
3. æ£€æŸ¥ç¨€ç–ç´¢å¼•æ˜¯å¦è¿‡å¤§

**è§£å†³æ–¹æ¡ˆ**:
```rust
// å¯ç”¨ Bloom Filter
config.enable_bloom_filter = true;

// å‡å°å—å¤§å° (å¢åŠ ç´¢å¼•å¯†åº¦)
config.block_size = 32 * 1024; // 32KB
```

### é—®é¢˜ 2: Compaction é˜»å¡å†™å…¥

**ç—‡çŠ¶**: å†™å…¥å»¶è¿Ÿçªç„¶å‡é«˜

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥ L0 æ–‡ä»¶æ•°
2. æ£€æŸ¥ Compaction çº¿ç¨‹æ˜¯å¦ç¹å¿™

**è§£å†³æ–¹æ¡ˆ**:
```rust
// å¢åŠ  L0 æ–‡ä»¶é˜ˆå€¼
config.l0_file_threshold = 8;

// å¢åŠ åå° Compaction çº¿ç¨‹
config.max_background_compactions = 4;
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [WAL è®¾è®¡](wal.md) - SSTable çš„æ•°æ®æ¥æº
- [MemTable å®ç°](memtable.md) - flush åˆ° SSTable
- [æŸ¥è¯¢å¼•æ“](query_engine.md) - å¦‚ä½•æŸ¥è¯¢ SSTable
- [Compaction è¯¦ç»†è®¾è®¡](../../storage/01_STORAGE_ARCHITECTURE.md#compaction) - å‹ç¼©ç­–ç•¥
- [Bloom Filter è®ºæ–‡](https://en.wikipedia.org/wiki/Bloom_filter) - åŸç†è¯¦è§£

---

[è¿”å›æ ¸å¿ƒæ¨¡å—](../README.md) | [è¿”å›æ–‡æ¡£ä¸­å¿ƒ](../../README.md)
