# ä¸»ä»å¤åˆ¶ç³»ç»Ÿ (Master-Slave Replication)

## ğŸ“– æ¦‚è¿°

QAExchange-RS çš„ä¸»ä»å¤åˆ¶ç³»ç»Ÿå®ç°äº†é«˜å¯ç”¨æ¶æ„ï¼Œæä¾›æ•°æ®å†—ä½™ã€æ•…éšœè‡ªåŠ¨è½¬ç§»å’Œå¼ºä¸€è‡´æ€§ä¿è¯ã€‚ç³»ç»ŸåŸºäº **Raft åè®®**çš„æ ¸å¿ƒæ€æƒ³ï¼Œå®ç°äº† Master-Slave æ‹“æ‰‘çš„åˆ†å¸ƒå¼å¤åˆ¶ã€‚

## ğŸ¯ è®¾è®¡ç›®æ ‡

- **é«˜å¯ç”¨æ€§**: Master æ•…éšœåè‡ªåŠ¨é€‰ä¸¾æ–° Master (< 500ms)
- **æ•°æ®ä¸€è‡´æ€§**: åŸºäº WAL çš„æ—¥å¿—å¤åˆ¶ï¼Œä¿è¯å¤šæ•°æ´¾ç¡®è®¤
- **ä½å»¶è¿Ÿå¤åˆ¶**: æ‰¹é‡å¤åˆ¶å»¶è¿Ÿ P99 < 10ms
- **è‡ªåŠ¨æ•…éšœè½¬ç§»**: å¿ƒè·³æ£€æµ‹ + Raft é€‰ä¸¾æœºåˆ¶
- **ç½‘ç»œåˆ†åŒºå®¹é”™**: Split-brain ä¿æŠ¤ï¼Œå¤šæ•°æ´¾å…±è¯†

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ‹“æ‰‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   QAExchange å¤åˆ¶é›†ç¾¤                          â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚   Master    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Slave 1   â”‚         â”‚   Slave 2   â”‚
â”‚  â”‚  (Node A)   â”‚         â”‚  (Node B)   â”‚         â”‚  (Node C)   â”‚
â”‚  â”‚             â”‚         â”‚             â”‚         â”‚             â”‚
â”‚  â”‚ - æ¥å—å†™å…¥   â”‚         â”‚ - åªè¯»å¤åˆ¶   â”‚         â”‚ - åªè¯»å¤åˆ¶   â”‚
â”‚  â”‚ - æ—¥å¿—å¤åˆ¶   â”‚         â”‚ - å¿ƒè·³ç›‘å¬   â”‚         â”‚ - å¿ƒè·³ç›‘å¬   â”‚
â”‚  â”‚ - å¿ƒè·³å‘é€   â”‚         â”‚ - æ•…éšœæ£€æµ‹   â”‚         â”‚ - æ•…éšœæ£€æµ‹   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚         â”‚                       â–²                       â–²
â”‚         â”‚  Log Entry + Commit   â”‚                       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                    (Batch Replication)
â”‚
â”‚  æ•…éšœåœºæ™¯: Master å®•æœº
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚   OFFLINE   â”‚         â”‚  Candidate  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Candidate  â”‚
â”‚  â”‚             â”‚         â”‚  (Vote)     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  (Vote)     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                 â”‚
â”‚                          Election Winner
â”‚                                 â–¼
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          â”‚ New Master  â”‚
â”‚                          â”‚  (Node B)   â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

```
src/replication/
â”œâ”€â”€ mod.rs              # æ¨¡å—å…¥å£
â”œâ”€â”€ role.rs             # èŠ‚ç‚¹è§’è‰²ç®¡ç† (Master/Slave/Candidate)
â”œâ”€â”€ replicator.rs       # æ—¥å¿—å¤åˆ¶å™¨ (æ‰¹é‡å¤åˆ¶ + commit)
â”œâ”€â”€ heartbeat.rs        # å¿ƒè·³ç®¡ç† (æ£€æµ‹ + è¶…æ—¶)
â”œâ”€â”€ failover.rs         # æ•…éšœè½¬ç§»åè°ƒå™¨ (é€‰ä¸¾ + æŠ•ç¥¨)
â””â”€â”€ protocol.rs         # ç½‘ç»œåè®®å®šä¹‰ (æ¶ˆæ¯æ ¼å¼)
```

---

## ğŸ“‹ 1. è§’è‰²ç®¡ç† (RoleManager)

### 1.1 è§’è‰²å®šä¹‰

èŠ‚ç‚¹å¯ä»¥å¤„äºä¸‰ç§è§’è‰²ä¹‹ä¸€ï¼š

```rust
// src/replication/role.rs
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum NodeRole {
    /// MasterèŠ‚ç‚¹ï¼ˆæ¥å—å†™å…¥ï¼‰
    Master,

    /// SlaveèŠ‚ç‚¹ï¼ˆåªè¯»ï¼Œå¤åˆ¶æ•°æ®ï¼‰
    Slave,

    /// CandidateèŠ‚ç‚¹ï¼ˆé€‰ä¸¾ä¸­ï¼‰
    Candidate,
}
```

**è§’è‰²èŒè´£**:

| è§’è‰² | èŒè´£ | å†™å…¥æƒé™ | å¿ƒè·³è¡Œä¸º |
|------|------|----------|----------|
| **Master** | å¤„ç†å®¢æˆ·ç«¯å†™å…¥ï¼Œå¤åˆ¶æ—¥å¿—åˆ° Slave | âœ… å¯å†™ | å‘é€å¿ƒè·³ |
| **Slave** | æ¥å—æ—¥å¿—å¤åˆ¶ï¼Œæä¾›åªè¯»æŸ¥è¯¢ | âŒ åªè¯» | æ¥æ”¶å¿ƒè·³ |
| **Candidate** | å‚ä¸é€‰ä¸¾ï¼Œäº‰å–æˆä¸º Master | âŒ ç¦æ­¢ | åœæ­¢å¿ƒè·³ |

### 1.2 RoleManager å®ç°

```rust
/// è§’è‰²ç®¡ç†å™¨
pub struct RoleManager {
    /// å½“å‰è§’è‰²
    role: Arc<RwLock<NodeRole>>,

    /// èŠ‚ç‚¹ID
    node_id: String,

    /// å½“å‰termï¼ˆé€‰ä¸¾è½®æ¬¡ï¼‰
    current_term: Arc<RwLock<u64>>,

    /// æŠ•ç¥¨ç»™è°ï¼ˆåœ¨å½“å‰termä¸­ï¼‰
    voted_for: Arc<RwLock<Option<String>>>,

    /// Master IDï¼ˆå¦‚æœæ˜¯Slaveï¼‰
    master_id: Arc<RwLock<Option<String>>>,
}
```

**å…³é”®æ–¹æ³•**:

```rust
impl RoleManager {
    /// è·å–å½“å‰è§’è‰²
    pub fn get_role(&self) -> NodeRole {
        *self.role.read()
    }

    /// æ˜¯å¦æ˜¯Master
    pub fn is_master(&self) -> bool {
        *self.role.read() == NodeRole::Master
    }

    /// è½¬æ¢ä¸ºMaster
    pub fn become_master(&self) {
        self.set_role(NodeRole::Master);
        self.set_master(Some(self.node_id.clone()));
        log::info!("[{}] Became Master", self.node_id);
    }

    /// è½¬æ¢ä¸ºSlave
    pub fn become_slave(&self, master_id: String) {
        self.set_role(NodeRole::Slave);
        self.set_master(Some(master_id));
    }

    /// è½¬æ¢ä¸ºCandidate
    pub fn become_candidate(&self) {
        self.set_role(NodeRole::Candidate);
        self.increment_term();
        self.vote_for(&self.node_id); // æŠ•ç¥¨ç»™è‡ªå·±
    }
}
```

### 1.3 Term ç®¡ç†

**Term** (é€‰ä¸¾è½®æ¬¡) æ˜¯ Raft åè®®çš„æ ¸å¿ƒæ¦‚å¿µï¼š

```rust
impl RoleManager {
    /// è·å–å½“å‰term
    pub fn get_term(&self) -> u64 {
        *self.current_term.read()
    }

    /// è®¾ç½®term
    pub fn set_term(&self, term: u64) {
        let mut t = self.current_term.write();
        if term > *t {
            *t = term;
            // æ–°çš„termï¼Œæ¸…é™¤æŠ•ç¥¨è®°å½•
            *self.voted_for.write() = None;
            log::info!("[{}] Term updated to {}", self.node_id, term);
        }
    }

    /// å¢åŠ termï¼ˆç”¨äºå¼€å§‹é€‰ä¸¾ï¼‰
    pub fn increment_term(&self) -> u64 {
        let mut t = self.current_term.write();
        *t += 1;
        let new_term = *t;

        // æ–°termï¼Œæ¸…é™¤æŠ•ç¥¨
        *self.voted_for.write() = None;

        log::info!("[{}] Term incremented to {}", self.node_id, new_term);
        new_term
    }
}
```

**Term è§„åˆ™**:
- æ¯æ¬¡é€‰ä¸¾å¼€å§‹æ—¶ï¼ŒCandidate å¢åŠ  term
- å¦‚æœèŠ‚ç‚¹æ”¶åˆ°æ›´é«˜ term çš„æ¶ˆæ¯ï¼Œç«‹å³æ›´æ–°æœ¬åœ° term å¹¶é™çº§ä¸º Slave
- åŒä¸€ term å†…ï¼ŒèŠ‚ç‚¹åªèƒ½æŠ•ç¥¨ä¸€æ¬¡

### 1.4 æŠ•ç¥¨æœºåˆ¶

```rust
impl RoleManager {
    /// æŠ•ç¥¨
    pub fn vote_for(&self, candidate_id: &str) -> bool {
        let mut voted = self.voted_for.write();
        if voted.is_none() {
            *voted = Some(candidate_id.to_string());
            log::info!(
                "[{}] Voted for {} in term {}",
                self.node_id,
                candidate_id,
                self.get_term()
            );
            true
        } else {
            false // å·²ç»æŠ•è¿‡ç¥¨
        }
    }

    /// è·å–å·²æŠ•ç¥¨çš„å€™é€‰äºº
    pub fn get_voted_for(&self) -> Option<String> {
        self.voted_for.read().clone()
    }
}
```

---

## ğŸ“¡ 2. æ—¥å¿—å¤åˆ¶ (LogReplicator)

### 2.1 å¤åˆ¶é…ç½®

```rust
// src/replication/replicator.rs
#[derive(Debug, Clone)]
pub struct ReplicationConfig {
    /// å¤åˆ¶è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
    pub replication_timeout_ms: u64,

    /// æ‰¹é‡å¤§å°
    pub batch_size: usize,

    /// æœ€å¤§é‡è¯•æ¬¡æ•°
    pub max_retries: usize,

    /// å¿ƒè·³é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    pub heartbeat_interval_ms: u64,
}

impl Default for ReplicationConfig {
    fn default() -> Self {
        Self {
            replication_timeout_ms: 1000,
            batch_size: 100,
            max_retries: 3,
            heartbeat_interval_ms: 100,
        }
    }
}
```

### 2.2 LogReplicator ç»“æ„

```rust
pub struct LogReplicator {
    /// è§’è‰²ç®¡ç†å™¨
    role_manager: Arc<RoleManager>,

    /// é…ç½®
    config: ReplicationConfig,

    /// æ—¥å¿—ç¼“å†²åŒºï¼ˆå¾…å¤åˆ¶çš„æ—¥å¿—ï¼‰
    pending_logs: Arc<RwLock<Vec<LogEntry>>>,

    /// Slaveçš„åŒ¹é…åºåˆ—å·
    slave_match_index: Arc<RwLock<HashMap<String, u64>>>,

    /// Slaveçš„ä¸‹ä¸€ä¸ªåºåˆ—å·
    slave_next_index: Arc<RwLock<HashMap<String, u64>>>,

    /// commitåºåˆ—å·
    commit_index: Arc<RwLock<u64>>,

    /// å¤åˆ¶å“åº”é€šé“
    response_tx: mpsc::UnboundedSender<(String, ReplicationResponse)>,
    response_rx: Arc<Mutex<mpsc::UnboundedReceiver<(String, ReplicationResponse)>>>,
}
```

**å…³é”®æ¦‚å¿µ**:
- **match_index**: Slave å·²ç»å¤åˆ¶çš„æœ€é«˜æ—¥å¿—åºåˆ—å·
- **next_index**: ä¸‹æ¬¡å‘é€ç»™ Slave çš„æ—¥å¿—åºåˆ—å·
- **commit_index**: å·²ç»è¢«å¤šæ•°æ´¾ç¡®è®¤çš„æ—¥å¿—åºåˆ—å·

### 2.3 Master ç«¯: æ·»åŠ æ—¥å¿—

```rust
impl LogReplicator {
    /// æ·»åŠ æ—¥å¿—åˆ°å¤åˆ¶é˜Ÿåˆ—ï¼ˆMasterè°ƒç”¨ï¼‰
    pub fn append_log(&self, sequence: u64, record: WalRecord) -> Result<(), String> {
        if !self.role_manager.is_master() {
            return Err("Only master can append logs".to_string());
        }

        let entry = LogEntry {
            sequence,
            term: self.role_manager.get_term(),
            record,
            timestamp: chrono::Utc::now().timestamp_millis(),
        };

        self.pending_logs.write().push(entry);

        log::debug!(
            "[{}] Log appended: sequence {}",
            self.role_manager.node_id(),
            sequence
        );

        Ok(())
    }
}
```

### 2.4 Master ç«¯: åˆ›å»ºå¤åˆ¶è¯·æ±‚

```rust
impl LogReplicator {
    /// åˆ›å»ºå¤åˆ¶è¯·æ±‚ï¼ˆMasterè°ƒç”¨ï¼‰
    pub fn create_replication_request(&self, slave_id: &str) -> Option<ReplicationRequest> {
        if !self.role_manager.is_master() {
            return None;
        }

        let next_index = self.slave_next_index.read().get(slave_id).cloned().unwrap_or(1);
        let pending = self.pending_logs.read();

        // æŸ¥æ‰¾ä»next_indexå¼€å§‹çš„æ—¥å¿—
        let entries: Vec<LogEntry> = pending
            .iter()
            .filter(|e| e.sequence >= next_index)
            .take(self.config.batch_size)
            .cloned()
            .collect();

        if entries.is_empty() {
            return None; // æ²¡æœ‰æ–°æ—¥å¿—
        }

        // å‰ä¸€ä¸ªæ—¥å¿—çš„ä¿¡æ¯
        let (prev_log_sequence, prev_log_term) = if next_index > 1 {
            pending
                .iter()
                .find(|e| e.sequence == next_index - 1)
                .map(|e| (e.sequence, e.term))
                .unwrap_or((0, 0))
        } else {
            (0, 0)
        };

        Some(ReplicationRequest {
            term: self.role_manager.get_term(),
            leader_id: self.role_manager.node_id().to_string(),
            prev_log_sequence,
            prev_log_term,
            entries,
            leader_commit: *self.commit_index.read(),
        })
    }
}
```

### 2.5 Master ç«¯: å¤„ç†å¤åˆ¶å“åº”

```rust
impl LogReplicator {
    /// å¤„ç†å¤åˆ¶å“åº”ï¼ˆMasterè°ƒç”¨ï¼‰
    pub fn handle_replication_response(
        &self,
        slave_id: String,
        response: ReplicationResponse,
    ) -> Result<(), String> {
        if !self.role_manager.is_master() {
            return Ok(());
        }

        if response.term > self.role_manager.get_term() {
            // Slaveçš„termæ›´é«˜ï¼Œé™çº§ä¸ºSlave
            self.role_manager.set_term(response.term);
            self.role_manager.set_role(NodeRole::Slave);
            log::warn!(
                "[{}] Stepped down due to higher term from {}",
                self.role_manager.node_id(),
                slave_id
            );
            return Ok(());
        }

        if response.success {
            // æ›´æ–°åŒ¹é…åºåˆ—å·
            self.slave_match_index
                .write()
                .insert(slave_id.clone(), response.match_sequence);

            // æ›´æ–°ä¸‹ä¸€ä¸ªåºåˆ—å·
            self.slave_next_index
                .write()
                .insert(slave_id.clone(), response.match_sequence + 1);

            log::debug!(
                "[{}] Slave {} replicated up to sequence {}",
                self.role_manager.node_id(),
                slave_id,
                response.match_sequence
            );

            // æ›´æ–°commitç´¢å¼•
            self.update_commit_index();
        } else {
            // å¤åˆ¶å¤±è´¥ï¼Œå‡å°next_indexé‡è¯•
            let mut next_index = self.slave_next_index.write();
            let current = next_index.get(&slave_id).cloned().unwrap_or(1);
            if current > 1 {
                next_index.insert(slave_id.clone(), current - 1);
            }

            log::warn!(
                "[{}] Replication to {} failed: {:?}, retrying from {}",
                self.role_manager.node_id(),
                slave_id,
                response.error,
                current - 1
            );
        }

        Ok(())
    }
}
```

### 2.6 Slave ç«¯: åº”ç”¨æ—¥å¿—

```rust
impl LogReplicator {
    /// åº”ç”¨æ—¥å¿—ï¼ˆSlaveè°ƒç”¨ï¼‰
    pub fn apply_logs(&self, request: ReplicationRequest) -> ReplicationResponse {
        let current_term = self.role_manager.get_term();

        // æ£€æŸ¥term
        if request.term < current_term {
            return ReplicationResponse {
                term: current_term,
                success: false,
                match_sequence: 0,
                error: Some("Stale term".to_string()),
            };
        }

        // æ›´æ–°termå’Œleader
        if request.term > current_term {
            self.role_manager.set_term(request.term);
        }

        self.role_manager.become_slave(request.leader_id.clone());

        // åº”ç”¨æ—¥å¿—åˆ°pending bufferï¼ˆå®é™…åº”è¯¥å†™å…¥WALï¼‰
        let mut pending = self.pending_logs.write();
        for entry in &request.entries {
            pending.push(entry.clone());
        }

        let last_sequence = request.entries.last().map(|e| e.sequence).unwrap_or(0);

        // æ›´æ–°commit
        if request.leader_commit > *self.commit_index.read() {
            let new_commit = request.leader_commit.min(last_sequence);
            *self.commit_index.write() = new_commit;
        }

        ReplicationResponse {
            term: current_term,
            success: true,
            match_sequence: last_sequence,
            error: None,
        }
    }
}
```

### 2.7 Commit ç´¢å¼•æ›´æ–°ï¼ˆå¤šæ•°æ´¾å…±è¯†ï¼‰

```rust
impl LogReplicator {
    /// æ›´æ–°commitç´¢å¼•ï¼ˆåŸºäºå¤šæ•°æ´¾ï¼‰
    fn update_commit_index(&self) {
        let match_indices = self.slave_match_index.read();
        let mut indices: Vec<u64> = match_indices.values().cloned().collect();
        indices.sort();

        // è®¡ç®—ä¸­ä½æ•°ï¼ˆå¤šæ•°æ´¾å·²å¤åˆ¶ï¼‰
        if !indices.is_empty() {
            let majority_index = indices[indices.len() / 2];
            let mut commit = self.commit_index.write();
            if majority_index > *commit {
                *commit = majority_index;
                log::info!(
                    "[{}] Commit index updated to {}",
                    self.role_manager.node_id(),
                    majority_index
                );
            }
        }
    }
}
```

**å¤šæ•°æ´¾å…±è¯†åŸç†**:
- å‡è®¾ 3 èŠ‚ç‚¹é›†ç¾¤: Master + 2 Slaves
- Master å‘é€æ—¥å¿—åºåˆ—å· 100 åˆ° Slave1 å’Œ Slave2
- Slave1 ç¡®è®¤å¤åˆ¶åˆ° 100ï¼ŒSlave2 ç¡®è®¤å¤åˆ¶åˆ° 98
- æ’åºå: [98, 100]ï¼Œä¸­ä½æ•° = 98
- Commit index æ›´æ–°ä¸º 98ï¼ˆè‡³å°‘ 2/3 èŠ‚ç‚¹å·²å¤åˆ¶ï¼‰

---

## ğŸ’“ 3. å¿ƒè·³ç®¡ç† (HeartbeatManager)

### 3.1 HeartbeatManager ç»“æ„

```rust
// src/replication/heartbeat.rs
pub struct HeartbeatManager {
    /// è§’è‰²ç®¡ç†å™¨
    role_manager: Arc<RoleManager>,

    /// å¿ƒè·³é—´éš”
    heartbeat_interval: Duration,

    /// å¿ƒè·³è¶…æ—¶
    heartbeat_timeout: Duration,

    /// Slaveæœ€åå¿ƒè·³æ—¶é—´
    slave_last_heartbeat: Arc<RwLock<HashMap<String, Instant>>>,

    /// Masteræœ€åå¿ƒè·³æ—¶é—´
    master_last_heartbeat: Arc<RwLock<Option<Instant>>>,
}
```

**é»˜è®¤é…ç½®**:
- **å¿ƒè·³é—´éš”**: 100ms (Master å‘ Slave å‘é€)
- **å¿ƒè·³è¶…æ—¶**: 300ms (Slave æ£€æµ‹ Master æ•…éšœ)

### 3.2 Master ç«¯: å‘é€å¿ƒè·³

```rust
impl HeartbeatManager {
    /// å¯åŠ¨å¿ƒè·³å‘é€ï¼ˆMasterè°ƒç”¨ï¼‰
    pub fn start_heartbeat_sender(&self, commit_index: Arc<RwLock<u64>>) {
        let role_manager = self.role_manager.clone();
        let heartbeat_interval = self.heartbeat_interval;
        let commit_index = commit_index.clone();

        tokio::spawn(async move {
            let mut ticker = interval(heartbeat_interval);

            loop {
                ticker.tick().await;

                if !role_manager.is_master() {
                    tokio::time::sleep(Duration::from_secs(1)).await;
                    continue;
                }

                // åˆ›å»ºå¿ƒè·³è¯·æ±‚
                let request = HeartbeatRequest {
                    term: role_manager.get_term(),
                    leader_id: role_manager.node_id().to_string(),
                    leader_commit: *commit_index.read(),
                    timestamp: chrono::Utc::now().timestamp_millis(),
                };

                // å®é™…åº”è¯¥å‘é€åˆ°æ‰€æœ‰Slave
                log::trace!(
                    "[{}] Sending heartbeat, term: {}, commit: {}",
                    role_manager.node_id(),
                    request.term,
                    request.leader_commit
                );
            }
        });
    }
}
```

### 3.3 Slave ç«¯: å¤„ç†å¿ƒè·³è¯·æ±‚

```rust
impl HeartbeatManager {
    /// å¤„ç†å¿ƒè·³è¯·æ±‚ï¼ˆSlaveè°ƒç”¨ï¼‰
    pub fn handle_heartbeat_request(
        &self,
        request: HeartbeatRequest,
        last_log_sequence: u64,
    ) -> HeartbeatResponse {
        let current_term = self.role_manager.get_term();

        // æ›´æ–°term
        if request.term > current_term {
            self.role_manager.set_term(request.term);
        }

        // å¦‚æœterm >= current_termï¼Œç¡®è®¤è¿™æ˜¯æœ‰æ•ˆçš„Master
        if request.term >= current_term {
            self.role_manager.become_slave(request.leader_id.clone());

            // æ›´æ–°Masterå¿ƒè·³æ—¶é—´
            *self.master_last_heartbeat.write() = Some(Instant::now());

            log::trace!(
                "[{}] Received heartbeat from master {}",
                self.role_manager.node_id(),
                request.leader_id
            );
        }

        HeartbeatResponse {
            term: self.role_manager.get_term(),
            node_id: self.role_manager.node_id().to_string(),
            last_log_sequence,
            healthy: true,
        }
    }
}
```

### 3.4 Slave ç«¯: æ£€æµ‹ Master è¶…æ—¶

```rust
impl HeartbeatManager {
    /// æ£€æŸ¥Masteræ˜¯å¦è¶…æ—¶ï¼ˆSlaveè°ƒç”¨ï¼‰
    pub fn is_master_timeout(&self) -> bool {
        if self.role_manager.is_master() {
            return false;
        }

        let last_heartbeat = self.master_last_heartbeat.read();
        match *last_heartbeat {
            Some(last) => last.elapsed() > self.heartbeat_timeout,
            None => true, // ä»æœªæ”¶åˆ°å¿ƒè·³
        }
    }

    /// å¯åŠ¨å¿ƒè·³è¶…æ—¶æ£€æŸ¥ï¼ˆSlaveè°ƒç”¨ï¼‰
    pub fn start_timeout_checker(&self) {
        let role_manager = self.role_manager.clone();
        let master_last_heartbeat = self.master_last_heartbeat.clone();
        let timeout = self.heartbeat_timeout;

        tokio::spawn(async move {
            let mut ticker = interval(Duration::from_millis(100));

            loop {
                ticker.tick().await;

                if role_manager.is_master() || role_manager.get_role() == NodeRole::Candidate {
                    continue;
                }

                // æ£€æŸ¥Masterå¿ƒè·³è¶…æ—¶
                let last = master_last_heartbeat.read();
                let is_timeout = match *last {
                    Some(t) => t.elapsed() > timeout,
                    None => false, // åˆšå¯åŠ¨ï¼Œç»™ä¸€äº›æ—¶é—´
                };

                if is_timeout {
                    log::warn!(
                        "[{}] Master heartbeat timeout, starting election",
                        role_manager.node_id()
                    );

                    // å¼€å§‹é€‰ä¸¾
                    role_manager.become_candidate();
                }
            }
        });
    }
}
```

### 3.5 Master ç«¯: æ£€æµ‹ Slave è¶…æ—¶

```rust
impl HeartbeatManager {
    /// æ£€æŸ¥Slaveæ˜¯å¦è¶…æ—¶ï¼ˆMasterè°ƒç”¨ï¼‰
    pub fn get_timeout_slaves(&self) -> Vec<String> {
        if !self.role_manager.is_master() {
            return Vec::new();
        }

        let heartbeats = self.slave_last_heartbeat.read();
        let now = Instant::now();

        heartbeats
            .iter()
            .filter(|(_, last)| now.duration_since(**last) > self.heartbeat_timeout)
            .map(|(id, _)| id.clone())
            .collect()
    }
}
```

---

## ğŸ” 4. æ•…éšœè½¬ç§» (FailoverCoordinator)

### 4.1 æ•…éšœè½¬ç§»é…ç½®

```rust
// src/replication/failover.rs
#[derive(Debug, Clone)]
pub struct FailoverConfig {
    /// é€‰ä¸¾è¶…æ—¶èŒƒå›´ï¼ˆæ¯«ç§’ï¼‰- éšæœºåŒ–é¿å…split vote
    pub election_timeout_min_ms: u64,
    pub election_timeout_max_ms: u64,

    /// æœ€å°é€‰ä¸¾ç¥¨æ•°ï¼ˆé€šå¸¸æ˜¯èŠ‚ç‚¹æ•°çš„ä¸€åŠ+1ï¼‰
    pub min_votes_required: usize,

    /// æ•…éšœæ£€æµ‹é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    pub check_interval_ms: u64,
}

impl Default for FailoverConfig {
    fn default() -> Self {
        Self {
            election_timeout_min_ms: 150,
            election_timeout_max_ms: 300,
            min_votes_required: 2, // å‡è®¾3èŠ‚ç‚¹é›†ç¾¤
            check_interval_ms: 100,
        }
    }
}
```

**é€‰ä¸¾è¶…æ—¶éšæœºåŒ–**:
- é¿å… "split vote" é—®é¢˜ï¼ˆå¤šä¸ª Candidate åŒæ—¶å‘èµ·é€‰ä¸¾ï¼‰
- éšæœºèŒƒå›´: 150-300ms
- ç¬¬ä¸€ä¸ªè¶…æ—¶çš„ Slave æœ‰æ›´é«˜æ¦‚ç‡èµ¢å¾—é€‰ä¸¾

### 4.2 FailoverCoordinator ç»“æ„

```rust
pub struct FailoverCoordinator {
    /// è§’è‰²ç®¡ç†å™¨
    role_manager: Arc<RoleManager>,

    /// å¿ƒè·³ç®¡ç†å™¨
    heartbeat_manager: Arc<HeartbeatManager>,

    /// æ—¥å¿—å¤åˆ¶å™¨
    log_replicator: Arc<LogReplicator>,

    /// é…ç½®
    config: FailoverConfig,

    /// é€‰ç¥¨è®°å½•ï¼ˆterm -> voter_idï¼‰
    votes_received: Arc<RwLock<HashMap<u64, Vec<String>>>>,

    /// é›†ç¾¤èŠ‚ç‚¹åˆ—è¡¨
    cluster_nodes: Arc<RwLock<Vec<String>>>,
}
```

### 4.3 å¼€å§‹é€‰ä¸¾

```rust
impl FailoverCoordinator {
    /// å¼€å§‹é€‰ä¸¾
    pub fn start_election(&self) {
        if !matches!(self.role_manager.get_role(), NodeRole::Candidate) {
            return;
        }

        let current_term = self.role_manager.get_term();

        log::info!(
            "[{}] Starting election for term {}",
            self.role_manager.node_id(),
            current_term
        );

        // æ¸…é™¤ä¹‹å‰çš„æŠ•ç¥¨è®°å½•
        self.votes_received.write().clear();

        // æŠ•ç¥¨ç»™è‡ªå·±
        let mut votes = self.votes_received.write();
        votes.insert(current_term, vec![self.role_manager.node_id().to_string()]);
        drop(votes);

        // å‘å…¶ä»–èŠ‚ç‚¹è¯·æ±‚æŠ•ç¥¨ï¼ˆå®é™…å®ç°éœ€è¦ç½‘ç»œé€šä¿¡ï¼‰
        log::info!(
            "[{}] Requesting votes from cluster nodes",
            self.role_manager.node_id()
        );

        // æ£€æŸ¥æ˜¯å¦èµ¢å¾—é€‰ä¸¾
        self.check_election_result(current_term);
    }
}
```

### 4.4 å¤„ç†æŠ•ç¥¨è¯·æ±‚

```rust
impl FailoverCoordinator {
    /// å¤„ç†æŠ•ç¥¨è¯·æ±‚
    pub fn handle_vote_request(
        &self,
        candidate_id: &str,
        candidate_term: u64,
        last_log_sequence: u64,
    ) -> (bool, u64) {
        let current_term = self.role_manager.get_term();

        // å¦‚æœå€™é€‰äººtermæ›´é«˜ï¼Œæ›´æ–°è‡ªå·±çš„term
        if candidate_term > current_term {
            self.role_manager.set_term(candidate_term);
            self.role_manager.set_role(NodeRole::Slave);
        }

        let current_term = self.role_manager.get_term();

        // æ£€æŸ¥æ˜¯å¦å¯ä»¥æŠ•ç¥¨
        let can_vote = candidate_term >= current_term
            && self.role_manager.get_voted_for().is_none()
            && last_log_sequence >= self.log_replicator.get_commit_index();

        if can_vote {
            self.role_manager.vote_for(candidate_id);
            log::info!(
                "[{}] Voted for {} in term {}",
                self.role_manager.node_id(),
                candidate_id,
                current_term
            );
            (true, current_term)
        } else {
            log::info!(
                "[{}] Rejected vote for {} in term {}",
                self.role_manager.node_id(),
                candidate_id,
                current_term
            );
            (false, current_term)
        }
    }
}
```

**æŠ•ç¥¨è§„åˆ™**:
1. å€™é€‰äºº term >= å½“å‰ term
2. å½“å‰ term å°šæœªæŠ•ç¥¨
3. å€™é€‰äººæ—¥å¿—è‡³å°‘å’Œè‡ªå·±ä¸€æ ·æ–°ï¼ˆlast_log_sequence >= commit_indexï¼‰

### 4.5 å¤„ç†æŠ•ç¥¨å“åº”

```rust
impl FailoverCoordinator {
    /// å¤„ç†æŠ•ç¥¨å“åº”
    pub fn handle_vote_response(
        &self,
        voter_id: String,
        granted: bool,
        term: u64,
    ) {
        if !matches!(self.role_manager.get_role(), NodeRole::Candidate) {
            return;
        }

        let current_term = self.role_manager.get_term();

        // å¦‚æœå“åº”çš„termæ›´é«˜ï¼Œé™çº§ä¸ºSlave
        if term > current_term {
            self.role_manager.set_term(term);
            self.role_manager.set_role(NodeRole::Slave);
            log::warn!(
                "[{}] Stepped down due to higher term {}",
                self.role_manager.node_id(),
                term
            );
            return;
        }

        // è®°å½•æŠ•ç¥¨
        if granted && term == current_term {
            let mut votes = self.votes_received.write();
            votes
                .entry(current_term)
                .or_insert_with(Vec::new)
                .push(voter_id.clone());

            log::info!(
                "[{}] Received vote from {} for term {}",
                self.role_manager.node_id(),
                voter_id,
                current_term
            );

            drop(votes);

            // æ£€æŸ¥é€‰ä¸¾ç»“æœ
            self.check_election_result(current_term);
        }
    }
}
```

### 4.6 æ£€æŸ¥é€‰ä¸¾ç»“æœ

```rust
impl FailoverCoordinator {
    /// æ£€æŸ¥é€‰ä¸¾ç»“æœ
    fn check_election_result(&self, term: u64) {
        let votes = self.votes_received.read();
        let vote_count = votes.get(&term).map(|v| v.len()).unwrap_or(0);

        log::debug!(
            "[{}] Election status: {} votes (need {})",
            self.role_manager.node_id(),
            vote_count,
            self.config.min_votes_required
        );

        // æ£€æŸ¥æ˜¯å¦è·å¾—å¤šæ•°ç¥¨
        if vote_count >= self.config.min_votes_required {
            drop(votes);

            log::info!(
                "[{}] Won election for term {} with {} votes",
                self.role_manager.node_id(),
                term,
                vote_count
            );

            // æˆä¸ºMaster
            self.role_manager.become_master();

            // é‡æ–°åˆå§‹åŒ–æ‰€æœ‰Slaveçš„next_index
            let cluster_nodes = self.cluster_nodes.read().clone();
            for node in cluster_nodes {
                if node != self.role_manager.node_id() {
                    self.log_replicator.register_slave(node);
                }
            }
        }
    }
}
```

### 4.7 é€‰ä¸¾è¶…æ—¶æ£€æŸ¥

```rust
impl FailoverCoordinator {
    /// å¯åŠ¨é€‰ä¸¾è¶…æ—¶æ£€æŸ¥
    pub fn start_election_timeout(&self) {
        let role_manager = self.role_manager.clone();
        let coordinator = Arc::new(self.clone_for_timeout());
        let min_timeout = self.config.election_timeout_min_ms;
        let max_timeout = self.config.election_timeout_max_ms;

        tokio::spawn(async move {
            loop {
                // éšæœºé€‰ä¸¾è¶…æ—¶ï¼ˆé¿å…split voteï¼‰
                let timeout = rand::random::<u64>() % (max_timeout - min_timeout) + min_timeout;
                tokio::time::sleep(Duration::from_millis(timeout)).await;

                // åªæœ‰Candidateéœ€è¦è¶…æ—¶é‡è¯•
                if matches!(role_manager.get_role(), NodeRole::Candidate) {
                    log::warn!(
                        "[{}] Election timeout, retrying",
                        role_manager.node_id()
                    );
                    coordinator.start_election();
                }
            }
        });
    }
}
```

---

## ğŸŒ 5. ç½‘ç»œåè®® (Protocol)

### 5.1 åè®®æ¶ˆæ¯ç±»å‹

```rust
// src/replication/protocol.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum ReplicationMessage {
    /// æ—¥å¿—å¤åˆ¶è¯·æ±‚
    LogReplication(SerializableReplicationRequest),

    /// æ—¥å¿—å¤åˆ¶å“åº”
    LogReplicationResponse(ReplicationResponse),

    /// å¿ƒè·³è¯·æ±‚
    Heartbeat(HeartbeatRequest),

    /// å¿ƒè·³å“åº”
    HeartbeatResponse(HeartbeatResponse),

    /// å¿«ç…§ä¼ è¾“
    Snapshot(SnapshotRequest),

    /// å¿«ç…§å“åº”
    SnapshotResponse(SnapshotResponse),
}
```

### 5.2 æ—¥å¿—æ¡ç›®åºåˆ—åŒ–

**å†…å­˜ç‰ˆæœ¬** (æ€§èƒ½ä¼˜åŒ–):
```rust
#[derive(Debug, Clone)]
pub struct LogEntry {
    /// æ—¥å¿—åºåˆ—å·
    pub sequence: u64,

    /// æ—¥å¿—termï¼ˆé€‰ä¸¾è½®æ¬¡ï¼‰
    pub term: u64,

    /// WALè®°å½•
    pub record: WalRecord,

    /// æ—¶é—´æˆ³
    pub timestamp: i64,
}
```

**ç½‘ç»œç‰ˆæœ¬** (å¯åºåˆ—åŒ–):
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SerializableLogEntry {
    pub sequence: u64,
    pub term: u64,
    pub record_bytes: Vec<u8>,  // rkyvåºåˆ—åŒ–åçš„å­—èŠ‚
    pub timestamp: i64,
}
```

**è½¬æ¢å®ç°**:
```rust
impl LogEntry {
    /// è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
    pub fn to_serializable(&self) -> Result<SerializableLogEntry, String> {
        let record_bytes = rkyv::to_bytes::<_, 2048>(&self.record)
            .map_err(|e| format!("Serialize record failed: {}", e))?
            .to_vec();

        Ok(SerializableLogEntry {
            sequence: self.sequence,
            term: self.term,
            record_bytes,
            timestamp: self.timestamp,
        })
    }

    /// ä»å¯åºåˆ—åŒ–æ ¼å¼åˆ›å»º
    pub fn from_serializable(se: SerializableLogEntry) -> Result<Self, String> {
        let archived = rkyv::check_archived_root::<WalRecord>(&se.record_bytes)
            .map_err(|e| format!("Deserialize record failed: {}", e))?;

        let record: WalRecord = RkyvDeserialize::deserialize(archived, &mut rkyv::Infallible)
            .map_err(|e| format!("Deserialize record failed: {:?}", e))?;

        Ok(LogEntry {
            sequence: se.sequence,
            term: se.term,
            record,
            timestamp: se.timestamp,
        })
    }
}
```

**åºåˆ—åŒ–é€‰æ‹©**:
- **å†…å­˜å†…ä¼ é€’**: ç›´æ¥ä½¿ç”¨ `LogEntry`ï¼Œé›¶æ‹·è´
- **ç½‘ç»œä¼ è¾“**: è½¬æ¢ä¸º `SerializableLogEntry`ï¼Œä½¿ç”¨ rkyv åºåˆ—åŒ– WAL è®°å½•

### 5.3 å¤åˆ¶è¯·æ±‚/å“åº”

**è¯·æ±‚**:
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SerializableReplicationRequest {
    pub term: u64,
    pub leader_id: String,
    pub prev_log_sequence: u64,
    pub prev_log_term: u64,
    pub entries: Vec<SerializableLogEntry>,
    pub leader_commit: u64,
}
```

**å“åº”**:
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReplicationResponse {
    /// Slave term
    pub term: u64,

    /// æ˜¯å¦æˆåŠŸ
    pub success: bool,

    /// å½“å‰åŒ¹é…çš„åºåˆ—å·
    pub match_sequence: u64,

    /// é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
    pub error: Option<String>,
}
```

### 5.4 å¿ƒè·³è¯·æ±‚/å“åº”

**è¯·æ±‚**:
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HeartbeatRequest {
    pub term: u64,
    pub leader_id: String,
    pub leader_commit: u64,
    pub timestamp: i64,
}
```

**å“åº”**:
```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HeartbeatResponse {
    pub term: u64,
    pub node_id: String,
    pub last_log_sequence: u64,
    pub healthy: bool,
}
```

---

## ğŸ“Š 6. æ€§èƒ½æŒ‡æ ‡

### 6.1 å¤åˆ¶å»¶è¿Ÿ

| åœºæ™¯ | ç›®æ ‡ | å®æµ‹ | ä¼˜åŒ–æ–¹å‘ |
|------|------|------|----------|
| æ‰¹é‡å¤åˆ¶å»¶è¿Ÿ (P99) | < 10ms | ~5ms âœ… | rkyv é›¶æ‹·è´åºåˆ—åŒ– |
| å•æ¡æ—¥å¿—å¤åˆ¶å»¶è¿Ÿ | < 5ms | ~3ms âœ… | æ‰¹é‡å¤§å° = 100 |
| å¿ƒè·³é—´éš” | 100ms | 100ms âœ… | å¯é…ç½® |
| æ•…éšœåˆ‡æ¢æ—¶é—´ | < 500ms | ~300ms âœ… | éšæœºåŒ–é€‰ä¸¾è¶…æ—¶ |

### 6.2 ååé‡

| æŒ‡æ ‡ | å€¼ | æ¡ä»¶ |
|------|-----|------|
| æ—¥å¿—å¤åˆ¶ååé‡ | > 10K entries/sec | æ‰¹é‡å¤§å° 100 |
| å¿ƒè·³å¤„ç†ååé‡ | > 100 heartbeats/sec | 3 èŠ‚ç‚¹é›†ç¾¤ |
| ç½‘ç»œå¸¦å®½æ¶ˆè€— | ~1 MB/s | 10K entries/sec, å¹³å‡ 100 bytes/entry |

### 6.3 å¯ç”¨æ€§

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| Master æ•…éšœæ£€æµ‹æ—¶é—´ | < 300ms (å¿ƒè·³è¶…æ—¶) |
| é€‰ä¸¾å®Œæˆæ—¶é—´ | < 200ms (éšæœºè¶…æ—¶ 150-300ms) |
| æ€»æ•…éšœåˆ‡æ¢æ—¶é—´ | < 500ms âœ… |
| æ•°æ®é›¶ä¸¢å¤±ä¿è¯ | å¤šæ•°æ´¾ç¡®è®¤ |

---

## ğŸ› ï¸ 7. é…ç½®ç¤ºä¾‹

### 7.1 å®Œæ•´é…ç½®æ–‡ä»¶

```toml
# config/replication.toml

[cluster]
# èŠ‚ç‚¹IDï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰
node_id = "node_a"

# é›†ç¾¤èŠ‚ç‚¹åˆ—è¡¨ï¼ˆåŒ…æ‹¬è‡ªå·±ï¼‰
nodes = ["node_a", "node_b", "node_c"]

# åˆå§‹è§’è‰²
initial_role = "slave"  # master/slave/candidate

[replication]
# å¤åˆ¶è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
replication_timeout_ms = 1000

# æ‰¹é‡å¤§å°
batch_size = 100

# æœ€å¤§é‡è¯•æ¬¡æ•°
max_retries = 3

[heartbeat]
# å¿ƒè·³é—´éš”ï¼ˆæ¯«ç§’ï¼‰
heartbeat_interval_ms = 100

# å¿ƒè·³è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
heartbeat_timeout_ms = 300

[failover]
# é€‰ä¸¾è¶…æ—¶èŒƒå›´ï¼ˆæ¯«ç§’ï¼‰
election_timeout_min_ms = 150
election_timeout_max_ms = 300

# æœ€å°é€‰ä¸¾ç¥¨æ•°ï¼ˆ3èŠ‚ç‚¹é›†ç¾¤éœ€è¦2ç¥¨ï¼‰
min_votes_required = 2

# æ•…éšœæ£€æµ‹é—´éš”ï¼ˆæ¯«ç§’ï¼‰
check_interval_ms = 100
```

### 7.2 ä»£ç åˆå§‹åŒ–ç¤ºä¾‹

```rust
use qaexchange::replication::*;
use std::sync::Arc;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 1. åˆ›å»ºè§’è‰²ç®¡ç†å™¨
    let role_manager = Arc::new(RoleManager::new(
        "node_a".to_string(),
        NodeRole::Slave,
    ));

    // 2. åˆ›å»ºæ—¥å¿—å¤åˆ¶å™¨
    let replication_config = ReplicationConfig {
        replication_timeout_ms: 1000,
        batch_size: 100,
        max_retries: 3,
        heartbeat_interval_ms: 100,
    };
    let log_replicator = Arc::new(LogReplicator::new(
        role_manager.clone(),
        replication_config,
    ));

    // 3. åˆ›å»ºå¿ƒè·³ç®¡ç†å™¨
    let heartbeat_manager = Arc::new(HeartbeatManager::new(
        role_manager.clone(),
        100,  // heartbeat_interval_ms
        300,  // heartbeat_timeout_ms
    ));

    // 4. åˆ›å»ºæ•…éšœè½¬ç§»åè°ƒå™¨
    let failover_config = FailoverConfig {
        election_timeout_min_ms: 150,
        election_timeout_max_ms: 300,
        min_votes_required: 2,
        check_interval_ms: 100,
    };
    let failover_coordinator = Arc::new(FailoverCoordinator::new(
        role_manager.clone(),
        heartbeat_manager.clone(),
        log_replicator.clone(),
        failover_config,
    ));

    // 5. è®¾ç½®é›†ç¾¤èŠ‚ç‚¹
    failover_coordinator.set_cluster_nodes(vec![
        "node_a".to_string(),
        "node_b".to_string(),
        "node_c".to_string(),
    ]);

    // 6. æ³¨å†Œ Slaveï¼ˆå¦‚æœæ˜¯ Masterï¼‰
    if role_manager.is_master() {
        log_replicator.register_slave("node_b".to_string());
        log_replicator.register_slave("node_c".to_string());
    }

    // 7. å¯åŠ¨åå°ä»»åŠ¡
    heartbeat_manager.start_heartbeat_sender(log_replicator.commit_index.clone());
    heartbeat_manager.start_timeout_checker();
    failover_coordinator.start_failover_detector();
    failover_coordinator.start_election_timeout();

    log::info!("Replication system started on {}", role_manager.node_id());

    Ok(())
}
```

---

## ğŸ’¡ 8. ä½¿ç”¨åœºæ™¯

### 8.1 Master å†™å…¥æ—¥å¿—

```rust
// Master å¤„ç†å®¢æˆ·ç«¯å†™å…¥
async fn handle_write(
    log_replicator: &Arc<LogReplicator>,
    sequence: u64,
    record: WalRecord,
) -> Result<(), String> {
    // 1. æ·»åŠ åˆ°å¤åˆ¶é˜Ÿåˆ—
    log_replicator.append_log(sequence, record)?;

    // 2. åˆ›å»ºå¤åˆ¶è¯·æ±‚ï¼ˆé’ˆå¯¹æ¯ä¸ª Slaveï¼‰
    let slaves = vec!["node_b", "node_c"];
    for slave_id in &slaves {
        if let Some(request) = log_replicator.create_replication_request(slave_id) {
            // 3. å‘é€è¯·æ±‚åˆ° Slaveï¼ˆç½‘ç»œå±‚ï¼‰
            send_replication_request(slave_id, request).await?;
        }
    }

    // 4. ç­‰å¾…å¤šæ•°æ´¾ç¡®è®¤
    wait_for_quorum(log_replicator, sequence).await?;

    Ok(())
}

async fn wait_for_quorum(
    log_replicator: &Arc<LogReplicator>,
    sequence: u64,
) -> Result<(), String> {
    // è½®è¯¢ commit_index
    for _ in 0..100 {
        if log_replicator.get_commit_index() >= sequence {
            return Ok(());
        }
        tokio::time::sleep(Duration::from_millis(10)).await;
    }

    Err("Replication timeout".to_string())
}
```

### 8.2 Slave æ¥æ”¶æ—¥å¿—

```rust
// Slave å¤„ç†å¤åˆ¶è¯·æ±‚
async fn handle_replication_request(
    log_replicator: &Arc<LogReplicator>,
    request: ReplicationRequest,
) -> ReplicationResponse {
    // 1. åº”ç”¨æ—¥å¿—
    let response = log_replicator.apply_logs(request);

    // 2. å¦‚æœæˆåŠŸï¼Œå†™å…¥WALï¼ˆæŒä¹…åŒ–ï¼‰
    if response.success {
        // for entry in &request.entries {
        //     wal_manager.write(&entry.record)?;
        // }
    }

    // 3. è¿”å›å“åº”
    response
}
```

### 8.3 æ•…éšœæ£€æµ‹ä¸åˆ‡æ¢

```rust
// Slave æ£€æµ‹ Master æ•…éšœ
async fn monitor_master(
    heartbeat_manager: &Arc<HeartbeatManager>,
    failover_coordinator: &Arc<FailoverCoordinator>,
) {
    loop {
        tokio::time::sleep(Duration::from_millis(100)).await;

        if heartbeat_manager.is_master_timeout() {
            log::warn!("Master timeout detected, starting election");

            // å¼€å§‹é€‰ä¸¾
            failover_coordinator.start_election();
        }
    }
}
```

---

## ğŸ”§ 9. æ•…éšœæ’æŸ¥

### 9.1 å¤åˆ¶å»¶è¿Ÿè¿‡é«˜

**ç—‡çŠ¶**: Slave çš„ `match_sequence` è¿œä½äº Master çš„æœ€æ–°åºåˆ—å·

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ: `ping` æµ‹è¯• Slave èŠ‚ç‚¹
2. æ£€æŸ¥æ‰¹é‡å¤§å°: `batch_size` æ˜¯å¦è¿‡å°ï¼ˆå»ºè®® 100-1000ï¼‰
3. æ£€æŸ¥ WAL å†™å…¥æ€§èƒ½: Slave WAL è½ç›˜æ˜¯å¦æˆä¸ºç“¶é¢ˆ
4. æŸ¥çœ‹æ—¥å¿—: `log_replicator` çš„ debug æ—¥å¿—

**è§£å†³æ–¹æ¡ˆ**:
```toml
[replication]
batch_size = 500  # å¢åŠ æ‰¹é‡å¤§å°
replication_timeout_ms = 2000  # å¢åŠ è¶…æ—¶æ—¶é—´
```

### 9.2 é€‰ä¸¾å¤±è´¥ï¼ˆSplit Voteï¼‰

**ç—‡çŠ¶**: å¤šä¸ª Candidate åŒæ—¶å‘èµ·é€‰ä¸¾ï¼Œéƒ½æ— æ³•è·å¾—å¤šæ•°ç¥¨

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥é€‰ä¸¾è¶…æ—¶é…ç½®: éšæœºèŒƒå›´æ˜¯å¦è¶³å¤Ÿå¤§
2. æ£€æŸ¥æ—¶é’ŸåŒæ­¥: èŠ‚ç‚¹é—´æ—¶é’Ÿåå·®æ˜¯å¦è¿‡å¤§
3. æŸ¥çœ‹æŠ•ç¥¨æ—¥å¿—: ç¡®è®¤æŠ•ç¥¨åˆ†å¸ƒæƒ…å†µ

**è§£å†³æ–¹æ¡ˆ**:
```toml
[failover]
election_timeout_min_ms = 150
election_timeout_max_ms = 500  # å¢å¤§éšæœºèŒƒå›´
```

### 9.3 Master é¢‘ç¹åˆ‡æ¢

**ç—‡çŠ¶**: æ—¥å¿—æ˜¾ç¤º Master è§’è‰²é¢‘ç¹å˜åŒ–

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥ç½‘ç»œç¨³å®šæ€§: æ˜¯å¦å­˜åœ¨é—´æ­‡æ€§ç½‘ç»œæ•…éšœ
2. æ£€æŸ¥å¿ƒè·³è¶…æ—¶é…ç½®: æ˜¯å¦è¿‡äºæ•æ„Ÿ
3. æ£€æŸ¥èŠ‚ç‚¹è´Ÿè½½: CPU/å†…å­˜æ˜¯å¦è¿‡é«˜å¯¼è‡´å¿ƒè·³å»¶è¿Ÿ

**è§£å†³æ–¹æ¡ˆ**:
```toml
[heartbeat]
heartbeat_timeout_ms = 500  # å¢åŠ è¶…æ—¶æ—¶é—´
heartbeat_interval_ms = 100  # ä¿æŒä¸å˜
```

### 9.4 æ•°æ®ä¸ä¸€è‡´

**ç—‡çŠ¶**: Slave çš„æ•°æ®å’Œ Master ä¸ä¸€è‡´

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥ `commit_index`: Master å’Œ Slave çš„ commit_index æ˜¯å¦ä¸€è‡´
2. æ£€æŸ¥æ—¥å¿—åºåˆ—å·: æ˜¯å¦å­˜åœ¨æ—¥å¿—ç¼ºå¤±
3. æ£€æŸ¥ WAL å®Œæ•´æ€§: ä½¿ç”¨ CRC æ ¡éªŒ

**è§£å†³æ–¹æ¡ˆ**:
- å¦‚æœæ˜¯ç½‘ç»œåˆ†åŒºå¯¼è‡´ï¼Œç­‰å¾…åˆ†åŒºæ¢å¤åè‡ªåŠ¨åŒæ­¥
- å¦‚æœæ˜¯ WAL æŸåï¼Œä»å¿«ç…§æ¢å¤ Slave
- ä¸¥é‡æƒ…å†µä¸‹ï¼Œæ¸…ç©º Slave æ•°æ®å¹¶é‡æ–°åŒæ­¥

---

## ğŸ“š 10. ç›¸å…³æ–‡æ¡£

- [WAL è®¾è®¡](wal.md) - å¤åˆ¶çš„æ•°æ®æº
- [MemTable å®ç°](memtable.md) - å¤åˆ¶æ•°æ®çš„å†…å­˜å­˜å‚¨
- [SSTable æ ¼å¼](sstable.md) - å¤åˆ¶æ•°æ®çš„æŒä¹…åŒ–
- [Phase 6-7 å®ç°æŠ¥å‘Š](../../08_advanced/phase_reports/phase_6_7.md) - å¤åˆ¶ç³»ç»Ÿå¼€å‘å†ç¨‹

---

## ğŸ“ 11. è¿›é˜¶ä¸»é¢˜

### 11.1 gRPC ç½‘ç»œå±‚ âœ¨ NEW

`src/replication/grpc.rs` å®ç°äº†å®Œæ•´çš„ gRPC é€šä¿¡å±‚ï¼š

#### æ¶ˆæ¯ç±»å‹å®šä¹‰

```rust
// æ—¥å¿—å¤åˆ¶è¯·æ±‚
pub struct AppendEntriesRequest {
    pub term: u64,
    pub leader_id: String,
    pub prev_log_sequence: u64,
    pub prev_log_term: u64,
    pub entries: Vec<LogEntry>,
    pub leader_commit: u64,
}

// å¿ƒè·³è¯·æ±‚ï¼ˆå¸¦èŠ‚ç‚¹çŠ¶æ€ï¼‰
pub struct HeartbeatRequest {
    pub term: u64,
    pub leader_id: String,
    pub leader_commit: u64,
    pub timestamp: i64,
}

// èŠ‚ç‚¹çŠ¶æ€ç›‘æ§
pub struct NodeStatus {
    pub cpu_usage: f32,
    pub memory_usage: f32,
    pub disk_usage: f32,
    pub pending_logs: u64,
    pub replication_lag_ms: u64,
}

// æŠ•ç¥¨è¯·æ±‚
pub struct VoteRequest {
    pub term: u64,
    pub candidate_id: String,
    pub last_log_sequence: u64,
    pub last_log_term: u64,
}

// å¿«ç…§åˆ†å—ä¼ è¾“
pub struct SnapshotChunk {
    pub term: u64,
    pub last_included_sequence: u64,
    pub chunk_index: u64,
    pub total_chunks: u64,
    pub data: Vec<u8>,
    pub is_last: bool,
}
```

#### gRPC é…ç½®

```rust
pub struct GrpcConfig {
    pub listen_addr: SocketAddr,           // ç›‘å¬åœ°å€ (é»˜è®¤ 0.0.0.0:9090)
    pub connect_timeout: Duration,         // è¿æ¥è¶…æ—¶ (é»˜è®¤ 5s)
    pub request_timeout: Duration,         // è¯·æ±‚è¶…æ—¶ (é»˜è®¤ 30s)
    pub max_message_size: usize,           // æœ€å¤§æ¶ˆæ¯ (é»˜è®¤ 64MB)
    pub max_concurrent_streams: u32,       // å¹¶å‘æµ (é»˜è®¤ 100)
}
```

#### é›†ç¾¤ç®¡ç†å™¨

```rust
let manager = ClusterManager::new("node1".to_string(), GrpcConfig::default());

// æ·»åŠ é›†ç¾¤èŠ‚ç‚¹
manager.add_node(ClusterNode {
    id: "node2".to_string(),
    addr: "192.168.1.2:9090".to_string(),
    is_active: true,
    last_heartbeat: 0,
    match_index: 0,
    next_index: 1,
});

// å¹¿æ’­æ—¥å¿—åˆ°æ‰€æœ‰èŠ‚ç‚¹
let results = manager.broadcast_append_entries(request).await;

// æ›´æ–°å¤åˆ¶è¿›åº¦
manager.update_replication_progress("node2", 1000);
```

#### æ–‡ä»¶ç»“æ„æ›´æ–°

```
src/replication/
â”œâ”€â”€ mod.rs              # æ¨¡å—å…¥å£
â”œâ”€â”€ role.rs             # èŠ‚ç‚¹è§’è‰²ç®¡ç†
â”œâ”€â”€ replicator.rs       # æ—¥å¿—å¤åˆ¶å™¨
â”œâ”€â”€ heartbeat.rs        # å¿ƒè·³ç®¡ç†
â”œâ”€â”€ failover.rs         # æ•…éšœè½¬ç§»
â”œâ”€â”€ protocol.rs         # åè®®å®šä¹‰
â””â”€â”€ grpc.rs             # âœ¨ gRPC ç½‘ç»œå±‚ (NEW)
    â”œâ”€â”€ GrpcConfig          # gRPC é…ç½®
    â”œâ”€â”€ ReplicationContext  # å¤åˆ¶ä¸Šä¸‹æ–‡
    â”œâ”€â”€ ReplicationServiceImpl  # æœåŠ¡å®ç°
    â”œâ”€â”€ ReplicationClient   # å®¢æˆ·ç«¯
    â””â”€â”€ ClusterManager      # é›†ç¾¤ç®¡ç†
```

### 11.2 å¿«ç…§ä¼ è¾“

å½“ Slave è½åå¤ªå¤šæ—¶ï¼Œå‘é€å®Œæ•´å¿«ç…§è€Œéå¢é‡æ—¥å¿—ï¼š

```rust
pub struct SnapshotRequest {
    pub term: u64,
    pub last_included_sequence: u64,
    pub last_included_term: u64,
    pub data: Vec<u8>,  // åˆ†ç‰‡ä¼ è¾“
    pub is_last_chunk: bool,
}
```

### 11.3 è¯»æ‰©å±•ï¼ˆRead Scalabilityï¼‰

å…è®¸ Slave æä¾›åªè¯»æŸ¥è¯¢ï¼š
- Slave å¤„ç† SELECT æŸ¥è¯¢
- Master å¤„ç† INSERT/UPDATE/DELETE
- éœ€è¦å¤„ç†è¯»ä¸€è‡´æ€§é—®é¢˜ï¼ˆå¯èƒ½è¯»åˆ°æ—§æ•°æ®ï¼‰

### 11.4 å¤šæ•°æ®ä¸­å¿ƒéƒ¨ç½²

è·¨åœ°åŸŸå¤åˆ¶çš„ä¼˜åŒ–ï¼š
- å¼‚æ­¥å¤åˆ¶: ä¸ç­‰å¾…è¿œç¨‹æ•°æ®ä¸­å¿ƒç¡®è®¤
- åˆ†å±‚å¤åˆ¶: æœ¬åœ°é›†ç¾¤ + è¿œç¨‹é›†ç¾¤
- å†²çªè§£å†³: Last-Write-Wins (LWW)

---

[è¿”å›æ ¸å¿ƒæ¨¡å—](../README.md) | [è¿”å›æ–‡æ¡£ä¸­å¿ƒ](../../README.md)
