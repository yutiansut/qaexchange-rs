# æŸ¥è¯¢å¼•æ“ (Polars DataFrame)

## ğŸ“– æ¦‚è¿°

QAExchange-RS çš„æŸ¥è¯¢å¼•æ“åŸºäº **Polars 0.51** DataFrame æ„å»ºï¼Œæä¾›é«˜æ€§èƒ½çš„æ•°æ®åˆ†æå’ŒæŸ¥è¯¢èƒ½åŠ›ã€‚æ”¯æŒ SQL æŸ¥è¯¢ã€ç»“æ„åŒ–æŸ¥è¯¢API å’Œæ—¶é—´åºåˆ—èšåˆã€‚

## ğŸ¯ è®¾è®¡ç›®æ ‡

- **é«˜æ€§èƒ½**: P99 < 10ms (100è¡ŒæŸ¥è¯¢)
- **çµæ´»æ€§**: æ”¯æŒ SQL å’Œç¼–ç¨‹ API
- **é›¶æ‹·è´**: LazyFrame å»¶è¿Ÿæ‰§è¡Œ
- **å¤§æ•°æ®**: æ‰«æåå > 1 GB/s
- **æ—¶é—´åºåˆ—**: åŸç”Ÿæ”¯æŒæ—¶é—´èšåˆ

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

```rust
// src/storage/query/engine.rs

use polars::prelude::*;
use polars::sql::SQLContext;

/// æŸ¥è¯¢å¼•æ“
pub struct QueryEngine {
    /// æ•°æ®æºç®¡ç†å™¨
    data_sources: Arc<RwLock<HashMap<String, DataFrame>>>,

    /// SQL ä¸Šä¸‹æ–‡
    sql_context: Arc<Mutex<SQLContext>>,

    /// æŸ¥è¯¢é…ç½®
    config: QueryConfig,
}

impl QueryEngine {
    /// åˆ›å»ºæŸ¥è¯¢å¼•æ“
    pub fn new(config: QueryConfig) -> Self {
        Self {
            data_sources: Arc::new(RwLock::new(HashMap::new())),
            sql_context: Arc::new(Mutex::new(SQLContext::new())),
            config,
        }
    }

    /// æ³¨å†Œæ•°æ®æº
    pub fn register_dataframe(&self, name: &str, df: DataFrame) -> Result<()> {
        // å­˜å‚¨åˆ°æ•°æ®æº
        self.data_sources.write().insert(name.to_string(), df.clone());

        // æ³¨å†Œåˆ° SQL ä¸Šä¸‹æ–‡
        let mut ctx = self.sql_context.lock();
        ctx.register(name, df.lazy());

        Ok(())
    }

    /// ä» SSTable åŠ è½½æ•°æ®æº
    pub fn load_from_sstable(&self, name: &str, sstable_path: &Path) -> Result<()> {
        // è¯»å– Parquet æ–‡ä»¶ (OLAP SSTable)
        let df = LazyFrame::scan_parquet(sstable_path, Default::default())?
            .collect()?;

        self.register_dataframe(name, df)
    }
}

#[derive(Debug, Clone)]
pub struct QueryConfig {
    /// æœ€å¤§æŸ¥è¯¢è¶…æ—¶ (ç§’)
    pub max_query_timeout_secs: u64,

    /// æ˜¯å¦å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢
    pub enable_parallelism: bool,

    /// å·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤ = CPU æ ¸æ•°)
    pub num_threads: Option<usize>,
}

impl Default for QueryConfig {
    fn default() -> Self {
        Self {
            max_query_timeout_secs: 300, // 5 åˆ†é’Ÿ
            enable_parallelism: true,
            num_threads: None, // è‡ªåŠ¨æ£€æµ‹
        }
    }
}
```

## ğŸ’¡ æŸ¥è¯¢æ–¹å¼

### 1. SQL æŸ¥è¯¢

#### åŸºç¡€æŸ¥è¯¢

```rust
impl QueryEngine {
    /// æ‰§è¡Œ SQL æŸ¥è¯¢
    pub fn execute_sql(&self, sql: &str) -> Result<DataFrame> {
        let mut ctx = self.sql_context.lock();

        // æ‰§è¡ŒæŸ¥è¯¢
        let lf = ctx.execute(sql)?;

        // æ”¶é›†ç»“æœ
        let df = lf.collect()?;

        Ok(df)
    }
}

// ä½¿ç”¨ç¤ºä¾‹
let engine = QueryEngine::new(Default::default());

// åŠ è½½æ•°æ®
engine.load_from_sstable("trades", Path::new("/data/trades.parquet"))?;
engine.load_from_sstable("orders", Path::new("/data/orders.parquet"))?;

// SQL æŸ¥è¯¢
let result = engine.execute_sql("
    SELECT
        instrument_id,
        COUNT(*) as trade_count,
        SUM(volume) as total_volume,
        AVG(price) as avg_price
    FROM trades
    WHERE timestamp > '2025-10-01'
    GROUP BY instrument_id
    ORDER BY total_volume DESC
    LIMIT 10
")?;

println!("{}", result);
```

#### JOIN æŸ¥è¯¢

```rust
let result = engine.execute_sql("
    SELECT
        o.order_id,
        o.user_id,
        t.trade_id,
        t.price,
        t.volume
    FROM orders o
    INNER JOIN trades t ON o.order_id = t.order_id
    WHERE o.user_id = 'user123'
    ORDER BY t.timestamp DESC
")?;
```

#### çª—å£å‡½æ•°

```rust
let result = engine.execute_sql("
    SELECT
        instrument_id,
        timestamp,
        price,
        AVG(price) OVER (
            PARTITION BY instrument_id
            ORDER BY timestamp
            ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
        ) as moving_avg_6
    FROM trades
    ORDER BY instrument_id, timestamp
")?;
```

### 2. ç»“æ„åŒ–æŸ¥è¯¢ API

#### åŸºæœ¬æ“ä½œ

```rust
impl QueryEngine {
    /// æ‰§è¡Œç»“æ„åŒ–æŸ¥è¯¢
    pub fn query(&self, request: StructuredQuery) -> Result<DataFrame> {
        // è·å–æ•°æ®æº
        let df = self.data_sources.read()
            .get(&request.table)
            .ok_or_else(|| anyhow!("Table not found: {}", request.table))?
            .clone();

        let mut lf = df.lazy();

        // åº”ç”¨è¿‡æ»¤
        if let Some(filter) = request.filter {
            lf = lf.filter(filter);
        }

        // é€‰æ‹©åˆ—
        if !request.columns.is_empty() {
            let cols: Vec<_> = request.columns.iter()
                .map(|c| col(c))
                .collect();
            lf = lf.select(&cols);
        }

        // æ’åº
        if let Some(sort) = request.sort {
            lf = lf.sort(&sort.column, sort.options);
        }

        // é™åˆ¶ç»“æœæ•°
        if let Some(limit) = request.limit {
            lf = lf.limit(limit);
        }

        // æ‰§è¡Œå¹¶æ”¶é›†
        lf.collect()
    }
}

#[derive(Debug, Clone)]
pub struct StructuredQuery {
    /// è¡¨å
    pub table: String,

    /// é€‰æ‹©çš„åˆ—
    pub columns: Vec<String>,

    /// è¿‡æ»¤æ¡ä»¶
    pub filter: Option<Expr>,

    /// æ’åº
    pub sort: Option<SortSpec>,

    /// é™åˆ¶ç»“æœæ•°
    pub limit: Option<usize>,
}

#[derive(Debug, Clone)]
pub struct SortSpec {
    pub column: String,
    pub options: SortOptions,
}

// ä½¿ç”¨ç¤ºä¾‹
let query = StructuredQuery {
    table: "trades".to_string(),
    columns: vec!["instrument_id".to_string(), "price".to_string(), "volume".to_string()],
    filter: Some(col("timestamp").gt(lit("2025-10-01"))),
    sort: Some(SortSpec {
        column: "timestamp".to_string(),
        options: SortOptions {
            descending: true,
            ..Default::default()
        },
    }),
    limit: Some(1000),
};

let result = engine.query(query)?;
```

#### èšåˆæŸ¥è¯¢

```rust
impl QueryEngine {
    /// æ‰§è¡ŒèšåˆæŸ¥è¯¢
    pub fn aggregate(&self, request: AggregateQuery) -> Result<DataFrame> {
        let df = self.data_sources.read()
            .get(&request.table)
            .ok_or_else(|| anyhow!("Table not found"))?
            .clone();

        let mut lf = df.lazy();

        // åº”ç”¨è¿‡æ»¤
        if let Some(filter) = request.filter {
            lf = lf.filter(filter);
        }

        // åˆ†ç»„èšåˆ
        let agg_exprs: Vec<_> = request.aggregations.iter()
            .map(|agg| match agg {
                AggregationType::Sum(col_name) => col(col_name).sum().alias(&format!("sum_{}", col_name)),
                AggregationType::Avg(col_name) => col(col_name).mean().alias(&format!("avg_{}", col_name)),
                AggregationType::Count => col("*").count().alias("count"),
                AggregationType::Min(col_name) => col(col_name).min().alias(&format!("min_{}", col_name)),
                AggregationType::Max(col_name) => col(col_name).max().alias(&format!("max_{}", col_name)),
            })
            .collect();

        if !request.group_by.is_empty() {
            let group_cols: Vec<_> = request.group_by.iter().map(|c| col(c)).collect();
            lf = lf.groupby(&group_cols).agg(&agg_exprs);
        } else {
            lf = lf.select(&agg_exprs);
        }

        // æ’åº
        if let Some(sort) = request.sort {
            lf = lf.sort(&sort.column, sort.options);
        }

        lf.collect()
    }
}

#[derive(Debug, Clone)]
pub struct AggregateQuery {
    pub table: String,
    pub group_by: Vec<String>,
    pub aggregations: Vec<AggregationType>,
    pub filter: Option<Expr>,
    pub sort: Option<SortSpec>,
}

#[derive(Debug, Clone)]
pub enum AggregationType {
    Sum(String),
    Avg(String),
    Count,
    Min(String),
    Max(String),
}

// ä½¿ç”¨ç¤ºä¾‹
let query = AggregateQuery {
    table: "trades".to_string(),
    group_by: vec!["instrument_id".to_string()],
    aggregations: vec![
        AggregationType::Count,
        AggregationType::Sum("volume".to_string()),
        AggregationType::Avg("price".to_string()),
    ],
    filter: Some(col("timestamp").gt(lit("2025-10-01"))),
    sort: Some(SortSpec {
        column: "sum_volume".to_string(),
        options: SortOptions { descending: true, ..Default::default() },
    }),
};

let result = engine.aggregate(query)?;
```

### 3. æ—¶é—´åºåˆ—æŸ¥è¯¢

#### æ—¶é—´ç²’åº¦èšåˆ

```rust
impl QueryEngine {
    /// æ—¶é—´åºåˆ—èšåˆæŸ¥è¯¢
    pub fn time_series_query(&self, request: TimeSeriesQuery) -> Result<DataFrame> {
        let df = self.data_sources.read()
            .get(&request.table)
            .ok_or_else(|| anyhow!("Table not found"))?
            .clone();

        let lf = df.lazy();

        // è§£ææ—¶é—´ç²’åº¦
        let duration = Self::parse_granularity(&request.granularity)?;

        // å‡†å¤‡èšåˆè¡¨è¾¾å¼
        let agg_exprs: Vec<_> = request.aggregations.iter()
            .map(|agg| match agg {
                AggregationType::Sum(col_name) => col(col_name).sum().alias(&format!("sum_{}", col_name)),
                AggregationType::Avg(col_name) => col(col_name).mean().alias(&format!("avg_{}", col_name)),
                AggregationType::Count => col("*").count().alias("count"),
                AggregationType::Min(col_name) => col(col_name).min().alias(&format!("min_{}", col_name)),
                AggregationType::Max(col_name) => col(col_name).max().alias(&format!("max_{}", col_name)),
            })
            .collect();

        // åŠ¨æ€åˆ†ç»„
        let result_lf = lf.groupby_dynamic(
            col(&request.time_column),
            [],  // ç©ºçš„é¢å¤–åˆ†ç»„åˆ—
            DynamicGroupOptions {
                every: duration,
                period: duration,
                offset: Duration::parse("0s")?,
                truncate: true,
                include_boundaries: false,
                closed_window: ClosedWindow::Left,
                start_by: StartBy::WindowBound,
            },
        )
        .agg(&agg_exprs);

        result_lf.collect()
    }

    /// è§£ææ—¶é—´ç²’åº¦å­—ç¬¦ä¸²
    fn parse_granularity(granularity: &str) -> Result<Duration> {
        match granularity {
            "1s" => Ok(Duration::parse("1s")?),
            "5s" => Ok(Duration::parse("5s")?),
            "10s" => Ok(Duration::parse("10s")?),
            "30s" => Ok(Duration::parse("30s")?),
            "1m" => Ok(Duration::parse("1m")?),
            "5m" => Ok(Duration::parse("5m")?),
            "15m" => Ok(Duration::parse("15m")?),
            "30m" => Ok(Duration::parse("30m")?),
            "1h" => Ok(Duration::parse("1h")?),
            "4h" => Ok(Duration::parse("4h")?),
            "1d" => Ok(Duration::parse("1d")?),
            other => Err(anyhow!("Unsupported granularity: {}", other)),
        }
    }
}

#[derive(Debug, Clone)]
pub struct TimeSeriesQuery {
    /// è¡¨å
    pub table: String,

    /// æ—¶é—´åˆ—å
    pub time_column: String,

    /// æ—¶é—´ç²’åº¦ ("1s", "1m", "5m", "1h", "1d" ç­‰)
    pub granularity: String,

    /// èšåˆæ“ä½œ
    pub aggregations: Vec<AggregationType>,

    /// æ—¶é—´èŒƒå›´ (å¯é€‰)
    pub time_range: Option<(i64, i64)>,
}

// ä½¿ç”¨ç¤ºä¾‹: è®¡ç®—æ¯åˆ†é’Ÿçš„ OHLCV
let query = TimeSeriesQuery {
    table: "trades".to_string(),
    time_column: "timestamp".to_string(),
    granularity: "1m".to_string(),
    aggregations: vec![
        AggregationType::Count,
        AggregationType::Sum("volume".to_string()),
        AggregationType::Avg("price".to_string()),
        AggregationType::Min("price".to_string()),
        AggregationType::Max("price".to_string()),
    ],
    time_range: Some((1696118400000, 1696204800000)), // 2023-10-01 to 2023-10-02
};

let ohlcv = engine.time_series_query(query)?;
```

#### Kçº¿ç”Ÿæˆ

```rust
impl QueryEngine {
    /// ç”Ÿæˆ K çº¿æ•°æ®
    pub fn generate_klines(
        &self,
        table: &str,
        granularity: &str,
        time_range: Option<(i64, i64)>,
    ) -> Result<DataFrame> {
        let df = self.data_sources.read()
            .get(table)
            .ok_or_else(|| anyhow!("Table not found"))?
            .clone();

        let mut lf = df.lazy();

        // åº”ç”¨æ—¶é—´è¿‡æ»¤
        if let Some((start, end)) = time_range {
            lf = lf.filter(
                col("timestamp").gt_eq(lit(start))
                    .and(col("timestamp").lt(lit(end)))
            );
        }

        // è§£æç²’åº¦
        let duration = Self::parse_granularity(granularity)?;

        // Kçº¿èšåˆ
        let kline_lf = lf.groupby_dynamic(
            col("timestamp"),
            [],
            DynamicGroupOptions {
                every: duration,
                period: duration,
                offset: Duration::parse("0s")?,
                truncate: true,
                include_boundaries: true,
                closed_window: ClosedWindow::Left,
                start_by: StartBy::WindowBound,
            },
        )
        .agg(&[
            col("price").first().alias("open"),
            col("price").max().alias("high"),
            col("price").min().alias("low"),
            col("price").last().alias("close"),
            col("volume").sum().alias("volume"),
            col("volume").count().alias("trade_count"),
        ]);

        kline_lf.collect()
    }
}

// ä½¿ç”¨ç¤ºä¾‹: ç”Ÿæˆ 5 åˆ†é’Ÿ K çº¿
let klines = engine.generate_klines(
    "trades",
    "5m",
    Some((1696118400000, 1696204800000)),
)?;

println!("{}", klines);
// è¾“å‡º:
// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
// â”‚ timestamp   â”‚ open   â”‚ high   â”‚ low    â”‚ close  â”‚ volume â”‚ trade_count â”‚
// â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
// â”‚ 2023-10-01  â”‚ 3250.0 â”‚ 3255.0 â”‚ 3248.0 â”‚ 3253.0 â”‚ 12500  â”‚ 45          â”‚
// â”‚ 00:00:00    â”‚        â”‚        â”‚        â”‚        â”‚        â”‚             â”‚
// â”‚ 2023-10-01  â”‚ 3253.0 â”‚ 3258.0 â”‚ 3252.0 â”‚ 3256.0 â”‚ 8900   â”‚ 32          â”‚
// â”‚ 00:05:00    â”‚        â”‚        â”‚        â”‚        â”‚        â”‚             â”‚
// â”‚ ...         â”‚ ...    â”‚ ...    â”‚ ...    â”‚ ...    â”‚ ...    â”‚ ...         â”‚
// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š SSTable æ‰«æå™¨

### OLAP SSTable æ‰«æ

```rust
// src/storage/query/scanner.rs

use arrow2::io::parquet::read::*;

pub struct SstableScanner {
    /// SSTable æ ¹ç›®å½•
    base_path: PathBuf,
}

impl SstableScanner {
    /// æ‰«ææ‰€æœ‰ Parquet æ–‡ä»¶
    pub fn scan_all_sstables(&self, instrument: &str) -> Result<DataFrame> {
        let pattern = format!("{}/{}/**/*.parquet", self.base_path.display(), instrument);
        let files = glob::glob(&pattern)?
            .filter_map(Result::ok)
            .collect::<Vec<_>>();

        if files.is_empty() {
            return Err(anyhow!("No SSTable files found for instrument: {}", instrument));
        }

        // ä½¿ç”¨ Polars scan_parquet æ‰¹é‡è¯»å–
        let lf = LazyFrame::scan_parquet_files(
            files,
            Default::default(),
        )?;

        lf.collect()
    }

    /// æ‰«ææŒ‡å®šæ—¶é—´èŒƒå›´
    pub fn scan_time_range(
        &self,
        instrument: &str,
        start_time: i64,
        end_time: i64,
    ) -> Result<DataFrame> {
        let df = self.scan_all_sstables(instrument)?;

        df.lazy()
            .filter(
                col("timestamp").gt_eq(lit(start_time))
                    .and(col("timestamp").lt(lit(end_time)))
            )
            .collect()
    }

    /// æ‰«æç‰¹å®šåˆ— (åˆ—å‰ªè£)
    pub fn scan_columns(
        &self,
        instrument: &str,
        columns: &[&str],
    ) -> Result<DataFrame> {
        let pattern = format!("{}/{}/**/*.parquet", self.base_path.display(), instrument);
        let files = glob::glob(&pattern)?
            .filter_map(Result::ok)
            .collect::<Vec<_>>();

        // Parquet è‡ªåŠ¨è¿›è¡Œåˆ—å‰ªè£
        let args = ScanArgsParquet {
            n_rows: None,
            cache: true,
            parallel: ParallelStrategy::Auto,
            rechunk: true,
            row_count: None,
            low_memory: false,
            cloud_options: None,
            use_statistics: true, // å¯ç”¨ç»Ÿè®¡ä¿¡æ¯åŠ é€Ÿ
        };

        let lf = LazyFrame::scan_parquet_files(files, args)?;

        // é€‰æ‹©åˆ—
        let cols: Vec<_> = columns.iter().map(|c| col(c)).collect();
        lf.select(&cols).collect()
    }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. LazyFrame å»¶è¿Ÿæ‰§è¡Œ

```rust
// âœ… æ¨è: ä½¿ç”¨ LazyFrame è¿›è¡ŒæŸ¥è¯¢ä¼˜åŒ–
let result = df.lazy()
    .filter(col("timestamp").gt(lit("2025-10-01")))
    .select(&[col("instrument_id"), col("price")])
    .groupby(&[col("instrument_id")])
    .agg(&[col("price").mean()])
    .sort("instrument_id", Default::default())
    .collect()?; // æœ€åæ‰æ‰§è¡Œ

// âŒ ä¸æ¨è: ç«‹å³æ‰§è¡Œæ¯ä¸ªæ“ä½œ
let result = df
    .filter(&col("timestamp").gt(lit("2025-10-01")))?
    .select(&["instrument_id", "price"])?
    .groupby(&["instrument_id"])?
    .mean()?;
```

**ä¼˜åŠ¿**:
- æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ– (predicate pushdown, projection pushdown)
- å‡å°‘ä¸­é—´æ•°æ®æ‹·è´
- è‡ªåŠ¨å¹¶è¡ŒåŒ–

### 2. è°“è¯ä¸‹æ¨ (Predicate Pushdown)

```rust
// Polars è‡ªåŠ¨å°†è¿‡æ»¤æ¡ä»¶ä¸‹æ¨åˆ° Parquet è¯»å–å±‚
let lf = LazyFrame::scan_parquet(path, Default::default())?
    .filter(col("timestamp").gt(lit("2025-10-01"))) // â† è‡ªåŠ¨ä¸‹æ¨
    .select(&[col("instrument_id"), col("price")]);  // â† åˆ—å‰ªè£

// åªè¯»å–æ»¡è¶³æ¡ä»¶çš„ Row Group å’Œåˆ—
let result = lf.collect()?;
```

### 3. åˆ—å‰ªè£ (Projection Pushdown)

```rust
// åªè¯»å–éœ€è¦çš„åˆ—ï¼Œå‡å°‘ I/O
let lf = LazyFrame::scan_parquet(path, Default::default())?
    .select(&[col("instrument_id"), col("price"), col("volume")]); // åªè¯»å–3åˆ—

let result = lf.collect()?;
```

### 4. å¹¶è¡ŒæŸ¥è¯¢

```rust
// è®¾ç½®å¹¶è¡Œåº¦
std::env::set_var("POLARS_MAX_THREADS", "8");

// æˆ–é€šè¿‡ API
let lf = df.lazy()
    .with_streaming(true) // å¯ç”¨æµå¼æ‰§è¡Œ
    .collect()?;
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

| æ“ä½œ | æ•°æ®é‡ | å»¶è¿Ÿ | åå | çŠ¶æ€ |
|------|--------|------|------|------|
| SQL æŸ¥è¯¢ (ç®€å•) | 100 rows | ~5ms | - | âœ… |
| SQL æŸ¥è¯¢ (JOIN) | 10K rows | ~35ms | - | âœ… |
| èšåˆæŸ¥è¯¢ | 100K rows | ~50ms | 2M rows/s | âœ… |
| æ—¶é—´åºåˆ—èšåˆ | 1M rows | ~120ms | 8M rows/s | âœ… |
| Parquet å…¨è¡¨æ‰«æ | 1GB | ~700ms | 1.5 GB/s | âœ… |
| Parquet åˆ—å‰ªè£ | 1GB (3/10 åˆ—) | ~250ms | 4 GB/s | âœ… |
| Parquet è°“è¯ä¸‹æ¨ | 1GB (1% åŒ¹é…) | ~50ms | 20 GB/s | âœ… |

## ğŸ› ï¸ é…ç½®ç¤ºä¾‹

```toml
# config/query.toml
[query_engine]
max_query_timeout_secs = 300
enable_parallelism = true
num_threads = 8  # æˆ–ç•™ç©ºè‡ªåŠ¨æ£€æµ‹

[lazy_frame]
enable_streaming = true
chunk_size = 100000

[parquet]
use_statistics = true  # å¯ç”¨ç»Ÿè®¡ä¿¡æ¯
parallel_strategy = "auto"  # "auto", "columns", "row_groups"
```

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½¿ç”¨ LazyFrame

```rust
// âœ… æ€»æ˜¯ä½¿ç”¨ LazyFrame
let result = df.lazy()
    .filter(...)
    .select(...)
    .groupby(...)
    .collect()?;

// âŒ é¿å…é“¾å¼ DataFrame æ“ä½œ
let result = df.filter(...)?.select(...)?.groupby(...)?;
```

### 2. æå‰è¿‡æ»¤æ•°æ®

```rust
// âœ… è¿‡æ»¤æ”¾åœ¨æœ€å‰é¢
let lf = df.lazy()
    .filter(col("timestamp").gt(lit("2025-10-01"))) // å…ˆè¿‡æ»¤
    .select(&cols)
    .groupby(&group_cols);

// âŒ è¿‡æ»¤æ”¾åœ¨åé¢
let lf = df.lazy()
    .select(&cols)
    .groupby(&group_cols)
    .filter(col("timestamp").gt(lit("2025-10-01"))); // åè¿‡æ»¤,æ•ˆç‡ä½
```

### 3. é€‰æ‹©åˆé€‚çš„èšåˆç²’åº¦

```rust
// å¯¹äºåˆ†é’Ÿçº§æ•°æ®,ä½¿ç”¨ 5m è€Œä¸æ˜¯ 1s
let query = TimeSeriesQuery {
    granularity: "5m".to_string(), // âœ… åˆç†ç²’åº¦
    // granularity: "1s".to_string(), // âŒ ç²’åº¦è¿‡ç»†
    ...
};
```

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æŸ¥è¯¢è¶…æ—¶

**ç—‡çŠ¶**: æŸ¥è¯¢æ‰§è¡Œè¶…è¿‡ 5 åˆ†é’Ÿ

**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ è¶…æ—¶æ—¶é—´
2. å¯ç”¨æµå¼æ‰§è¡Œ
3. å‡å°‘æ•°æ®é‡ (æ—¶é—´èŒƒå›´è¿‡æ»¤)

```rust
config.max_query_timeout_secs = 600; // 10 åˆ†é’Ÿ

// å¯ç”¨æµå¼æ‰§è¡Œ
let lf = df.lazy()
    .with_streaming(true)
    .collect()?;
```

### é—®é¢˜ 2: å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: OOM (Out of Memory)

**è§£å†³æ–¹æ¡ˆ**:
1. ä½¿ç”¨ LazyFrame å»¶è¿Ÿæ‰§è¡Œ
2. å¯ç”¨æµå¼æ‰§è¡Œ
3. åˆ†æ‰¹å¤„ç†æ•°æ®

```rust
// æµå¼å¤„ç†å¤§æ•°æ®
let lf = LazyFrame::scan_parquet(path, Default::default())?
    .with_streaming(true);

// æˆ–åˆ†æ‰¹è¯»å–
for chunk in lf.collect_chunked()? {
    process_chunk(chunk)?;
}
```

### é—®é¢˜ 3: Parquet è¯»å–æ…¢

**ç—‡çŠ¶**: æ‰«æ 1GB Parquet æ–‡ä»¶ > 2 ç§’

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥æ˜¯å¦å¯ç”¨åˆ—å‰ªè£
2. æ£€æŸ¥æ˜¯å¦å¯ç”¨è°“è¯ä¸‹æ¨
3. æ£€æŸ¥å¹¶è¡Œåº¦è®¾ç½®

**è§£å†³æ–¹æ¡ˆ**:
```rust
let args = ScanArgsParquet {
    use_statistics: true,  // å¯ç”¨ç»Ÿè®¡ä¿¡æ¯
    parallel: ParallelStrategy::Auto, // è‡ªåŠ¨å¹¶è¡Œ
    ..Default::default()
};

let lf = LazyFrame::scan_parquet_files(files, args)?
    .filter(col("timestamp").gt(lit("2025-10-01"))) // è°“è¯ä¸‹æ¨
    .select(&[col("price"), col("volume")]); // åˆ—å‰ªè£
```

## ğŸ”„ æµæ‰¹æ··åˆæŸ¥è¯¢ âœ¨ NEW

`src/query/hybrid.rs` æä¾›æµå¼å’Œæ‰¹å¤„ç†æ··åˆçš„æŸ¥è¯¢èƒ½åŠ›ï¼š

### æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  æµæ‰¹æ··åˆæŸ¥è¯¢æ¶æ„                             â”‚
â”‚                                                             â”‚
â”‚    Client Query                                             â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼                                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚    â”‚         HybridQueryEngine           â”‚                 â”‚
â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                 â”‚
â”‚    â”‚  â”‚ StreamBufferâ”‚   BatchSource   â”‚  â”‚                 â”‚
â”‚    â”‚  â”‚  (å®æ—¶æ•°æ®)  â”‚   (å†å²æ•°æ®)    â”‚  â”‚                 â”‚
â”‚    â”‚  â”‚  DashMap    â”‚   Parquet/SST   â”‚  â”‚                 â”‚
â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                 â”‚
â”‚    â”‚           â”‚               â”‚         â”‚                 â”‚
â”‚    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚                 â”‚
â”‚    â”‚                   â–¼                 â”‚                 â”‚
â”‚    â”‚           MergeStrategy             â”‚                 â”‚
â”‚    â”‚   (ByTimestamp/StreamFirst/Latest)  â”‚                 â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                   â”‚                                         â”‚
â”‚                   â–¼                                         â”‚
â”‚            QueryResult                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æµæ•°æ®ç¼“å­˜ (StreamBuffer)

```rust
use qaexchange::query::hybrid::{StreamBuffer, Record, RecordValue};

// åˆ›å»ºæµç¼“å­˜ï¼ˆæœ€å¤§ 5 åˆ†é’Ÿï¼Œæœ€å¤š 10000 æ¡ï¼‰
let buffer = StreamBuffer::new(Duration::from_secs(300), 10000);

// æ¨é€å®æ—¶æ•°æ®
buffer.push(Record::new("cu2501", timestamp)
    .with_value("price", RecordValue::Float(85000.0))
    .with_value("volume", RecordValue::Int(100)));

// æŸ¥è¯¢æœ€æ–° N æ¡
let latest = buffer.query_latest("cu2501", 10);

// æŸ¥è¯¢æ—¶é—´èŒƒå›´
let range = buffer.query_range("cu2501", start_ts, end_ts);
```

### æ··åˆæŸ¥è¯¢å¼•æ“

```rust
use qaexchange::query::hybrid::{HybridQueryEngine, HybridConfig, MergeStrategy};

// é…ç½®æ··åˆæŸ¥è¯¢
let config = HybridConfig {
    stream_max_latency: Duration::from_millis(100),  // æµæ•°æ®æœ€å¤§å»¶è¿Ÿ
    batch_timeout: Duration::from_secs(30),           // æ‰¹æŸ¥è¯¢è¶…æ—¶
    merge_strategy: MergeStrategy::ByTimestamp,       // æŒ‰æ—¶é—´æˆ³åˆå¹¶
    stream_priority_window: Duration::from_secs(60),  // 1åˆ†é’Ÿå†…ä¼˜å…ˆæµæ•°æ®
};

let engine = HybridQueryEngine::new(config)
    .with_batch_source(batch_data_source);

// æ‰§è¡Œæ··åˆæŸ¥è¯¢
let result = engine.query(
    "cu2501",
    start_ts,
    end_ts,
    &["price".to_string(), "volume".to_string()],
).await?;

println!("æ¥æº: {:?}", result.source);  // DataSource::Merged
println!("è®°å½•æ•°: {}", result.records.len());
println!("æ‰§è¡Œæ—¶é—´: {:?}", result.execution_time);
```

### åˆå¹¶ç­–ç•¥

| ç­–ç•¥ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| `StreamFirst` | æµæ•°æ®ä¼˜å…ˆï¼Œæ‰¹æ•°æ®è¡¥å……æ—§æ•°æ® | å®æ—¶æ€§è¦æ±‚é«˜ |
| `BatchFirst` | æ‰¹æ•°æ®ä¼˜å…ˆï¼Œæµæ•°æ®è¡¥å……æ–°æ•°æ® | æ•°æ®ä¸€è‡´æ€§è¦æ±‚é«˜ |
| `ByTimestamp` | æŒ‰æ—¶é—´æˆ³åˆå¹¶å»é‡ | é€šç”¨åœºæ™¯ |
| `Latest` | å–æœ€æ–°æ•°æ® | åªå…³å¿ƒæœ€æ–°çŠ¶æ€ |

### æ‰¹å¤„ç†æ•°æ®æºæ¥å£

```rust
#[async_trait]
pub trait BatchDataSource: Send + Sync {
    /// æŸ¥è¯¢å†å²æ•°æ®
    async fn query(
        &self,
        key: &str,
        start_ts: i64,
        end_ts: i64,
        fields: &[String],
    ) -> Result<Vec<Record>, BatchQueryError>;

    /// èšåˆæŸ¥è¯¢
    async fn aggregate(
        &self,
        key: &str,
        start_ts: i64,
        end_ts: i64,
        aggregations: &[Aggregation],
    ) -> Result<AggregateResult, BatchQueryError>;
}
```

### èšåˆæ“ä½œ

```rust
use qaexchange::query::hybrid::{Aggregation, AggregateOp};

let aggregations = vec![
    Aggregation { field: "price".to_string(), op: AggregateOp::Avg, alias: "avg_price".to_string() },
    Aggregation { field: "volume".to_string(), op: AggregateOp::Sum, alias: "total_volume".to_string() },
    Aggregation { field: "price".to_string(), op: AggregateOp::Max, alias: "high".to_string() },
    Aggregation { field: "price".to_string(), op: AggregateOp::Min, alias: "low".to_string() },
];
```

### æ€§èƒ½æŒ‡æ ‡

| æ“ä½œ | å»¶è¿Ÿ | è¯´æ˜ |
|------|------|------|
| StreamBuffer.push() | ~50 ns | DashMap å†™å…¥ |
| StreamBuffer.query_latest() | ~200 ns | DashMap è¯»å– |
| HybridQuery (ç¼“å­˜å‘½ä¸­) | < 1 ms | æµæ•°æ®ç›´æ¥è¿”å› |
| HybridQuery (æ‰¹æŸ¥è¯¢) | < 50 ms | Parquet æ‰«æ + åˆå¹¶ |

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [SSTable æ ¼å¼](sstable.md) - Parquet SSTable è¯¦ç»†æ ¼å¼
- [MemTable å®ç°](memtable.md) - OLAP MemTable ä¸æŸ¥è¯¢å¼•æ“é›†æˆ
- [å› å­è®¡ç®—ç³»ç»Ÿ](../factor/README.md) - å› å­ DAG ä¸æŸ¥è¯¢å¼•æ“é›†æˆ
- [Polars å®˜æ–¹æ–‡æ¡£](https://pola-rs.github.io/polars-book/) - å®Œæ•´ API å‚è€ƒ
- [Arrow2 æ–‡æ¡£](https://jorgecarleitao.github.io/arrow2/) - åº•å±‚åˆ—å¼æ ¼å¼
- [æŸ¥è¯¢å¼•æ“è¯¦ç»†è®¾è®¡](../../storage/05_ARROW2_QUERY_ENGINE.md) - æ¶æ„ç»†èŠ‚

---

[è¿”å›æ ¸å¿ƒæ¨¡å—](../README.md) | [è¿”å›æ–‡æ¡£ä¸­å¿ƒ](../../README.md)
